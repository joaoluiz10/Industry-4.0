{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente é necessário importar os dos dados coletados e dividi-lo em conjuntos de teste e validação "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recebe os CSVs dos novos sinais gerados, divide em banco de dados de treino e teste, cria os bancos de dados\n",
    "# de entradas e labels integrados e com todos os valores gerados para treinar a MLP  \n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "lenght_signal = 850 # Precisa ser o mesmo número usado no programa \"Desafio 2 - Gerador de Sinais\"\n",
    "tamanho_test = 0.2 # tamanho do conjunto de teste em porcentagem\n",
    "\n",
    "#Parte 1 - Recepção dos dados e separação dos conjuntos de teste e validação de cada classe\n",
    "# ENTRADA da Classe 0\n",
    "dataset = pd.read_csv(\"Sinal do elevador correto.csv\") \n",
    "dataset = dataset.drop(columns =['Unnamed: 0'])\n",
    "train = dataset.drop(columns =[str(lenght_signal)]) \n",
    "label = dataset[[str(lenght_signal)]]\n",
    "X_train0, X_test0, y_train0, y_test0 = train_test_split(train, label, test_size=tamanho_test) # separa 20% dos valores para validação.  A vantagem de separar os dados\n",
    "                                                                                    # de validação por classe garante uma distribuição homogênea para treinamento\n",
    "                                                                                    \n",
    "# ENTRADA da Classe 1\n",
    "dataset = pd.read_csv(\"Sinal do elevador falha_acel.csv\")\n",
    "dataset = dataset.drop(columns =['Unnamed: 0'])\n",
    "train = dataset.drop(columns =[str(lenght_signal)]) \n",
    "label = dataset[[str(lenght_signal)]]\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(train, label, test_size=tamanho_test) # separa 20% dos valores para validação \n",
    "\n",
    "# ENTRADA da Classe 2\n",
    "dataset = pd.read_csv(\"Sinal do elevador falha_vel.csv\") \n",
    "dataset = dataset.drop(columns =['Unnamed: 0'])\n",
    "train = dataset.drop(columns =[str(lenght_signal)]) \n",
    "label = dataset[[str(lenght_signal)]]\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(train, label, test_size=tamanho_test) # separa 20% dos valores para validação \n",
    "\n",
    "# ENTRADA da Classe 3\n",
    "dataset = pd.read_csv(\"Sinal do elevador ruido_desl.csv\")\n",
    "dataset = dataset.drop(columns =['Unnamed: 0'])\n",
    "train = dataset.drop(columns =[str(lenght_signal)]) \n",
    "label = dataset[[str(lenght_signal)]]\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(train, label, test_size=tamanho_test) # separa 20% dos valores para validação \n",
    "\n",
    "# Junta todas as classes de entradas em um só banco de dados de treino\n",
    "new_sheet = pd.concat([X_train0, X_train1, X_train2, X_train3], axis=0,sort=False) \n",
    "new_sheet_list = pd.concat([y_train0, y_train1, y_train2, y_train3], axis=0,sort=False)\n",
    "new_sheet[lenght_signal] = new_sheet_list # coloca as labels na última coluna para embralhar no comando seguinte\n",
    "new_sheet_shuffled = shuffle(new_sheet) # embaralha as entradas para deixar o treinamento da MLP otimizado com menos chance de \n",
    "                                # de se prender a mínimos locais\n",
    "trainX = new_sheet_shuffled.drop(columns =[lenght_signal]) # conjunto de treino\n",
    "trainy = new_sheet_shuffled[[lenght_signal]]    # labels do conjunto de treino\n",
    "\n",
    "\n",
    "# Junta todas as classes de entradas em um só banco de dados de validação\n",
    "testX = pd.concat([X_test0, X_test1, X_test2, X_test3], axis=0,sort=False) # conjunto de validação\n",
    "testy = pd.concat([y_test0, y_test1, y_test2, y_test3], axis=0,sort=False) # labels do conjunto de validação\n",
    "\n",
    "\n",
    "#Plot a row of X_train\n",
    "#row = X_train.iloc[1]\n",
    "#plt.plot(row)\n",
    "\n",
    "# Salva os dados gerados em CSVs\n",
    "trainX.to_csv('input_train.csv',  index=False)\n",
    "trainy.to_csv('label_input_train.csv',  index=False)\n",
    "testX.to_csv('input_validation.csv',  index=False)\n",
    "testy.to_csv('label_input_validation.csv',  index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de agora inicia a criação e treino da MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 1.3520 - accuracy: 0.3375 - val_loss: 1.3154 - val_accuracy: 0.4469\n",
      "Epoch 2/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 1.3092 - accuracy: 0.3930 - val_loss: 1.2870 - val_accuracy: 0.4500\n",
      "Epoch 3/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 1.2777 - accuracy: 0.4320 - val_loss: 1.2612 - val_accuracy: 0.4688\n",
      "Epoch 4/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 1.2516 - accuracy: 0.4547 - val_loss: 1.2500 - val_accuracy: 0.3938\n",
      "Epoch 5/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 1.2297 - accuracy: 0.4641 - val_loss: 1.2235 - val_accuracy: 0.4500\n",
      "Epoch 6/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 1.2065 - accuracy: 0.4578 - val_loss: 1.1940 - val_accuracy: 0.5500\n",
      "Epoch 7/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 1.1830 - accuracy: 0.4805 - val_loss: 1.1853 - val_accuracy: 0.4563\n",
      "Epoch 8/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 1.1654 - accuracy: 0.4953 - val_loss: 1.1664 - val_accuracy: 0.4500\n",
      "Epoch 9/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 1.1479 - accuracy: 0.4812 - val_loss: 1.1574 - val_accuracy: 0.4500\n",
      "Epoch 10/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 1.1316 - accuracy: 0.4938 - val_loss: 1.1360 - val_accuracy: 0.5063\n",
      "Epoch 11/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 1.1190 - accuracy: 0.5141 - val_loss: 1.1187 - val_accuracy: 0.5125\n",
      "Epoch 12/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 1.1061 - accuracy: 0.5055 - val_loss: 1.1257 - val_accuracy: 0.4500\n",
      "Epoch 13/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 1.0948 - accuracy: 0.5172 - val_loss: 1.0999 - val_accuracy: 0.4844\n",
      "Epoch 14/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 1.0775 - accuracy: 0.5328 - val_loss: 1.0905 - val_accuracy: 0.4313\n",
      "Epoch 15/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 1.0709 - accuracy: 0.5188 - val_loss: 1.0810 - val_accuracy: 0.4969\n",
      "Epoch 16/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 1.0584 - accuracy: 0.5289 - val_loss: 1.0620 - val_accuracy: 0.5000\n",
      "Epoch 17/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 1.0446 - accuracy: 0.5336 - val_loss: 1.0817 - val_accuracy: 0.4625\n",
      "Epoch 18/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 1.0399 - accuracy: 0.5484 - val_loss: 1.0442 - val_accuracy: 0.5281\n",
      "Epoch 19/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 1.0297 - accuracy: 0.5484 - val_loss: 1.0368 - val_accuracy: 0.5531\n",
      "Epoch 20/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 1.0205 - accuracy: 0.5445 - val_loss: 1.0288 - val_accuracy: 0.5813\n",
      "Epoch 21/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 1.0151 - accuracy: 0.5547 - val_loss: 1.0222 - val_accuracy: 0.5625\n",
      "Epoch 22/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 1.0049 - accuracy: 0.5508 - val_loss: 1.0181 - val_accuracy: 0.5312\n",
      "Epoch 23/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 1.0018 - accuracy: 0.5555 - val_loss: 1.0056 - val_accuracy: 0.5344\n",
      "Epoch 24/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.9930 - accuracy: 0.5625 - val_loss: 1.0020 - val_accuracy: 0.5281\n",
      "Epoch 25/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.9927 - accuracy: 0.5453 - val_loss: 0.9895 - val_accuracy: 0.5500\n",
      "Epoch 26/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.9778 - accuracy: 0.5641 - val_loss: 1.0437 - val_accuracy: 0.4625\n",
      "Epoch 27/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.9785 - accuracy: 0.5719 - val_loss: 0.9817 - val_accuracy: 0.5531\n",
      "Epoch 28/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.9717 - accuracy: 0.5641 - val_loss: 0.9732 - val_accuracy: 0.5781\n",
      "Epoch 29/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.9645 - accuracy: 0.5695 - val_loss: 0.9722 - val_accuracy: 0.5281\n",
      "Epoch 30/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.9612 - accuracy: 0.5594 - val_loss: 0.9891 - val_accuracy: 0.5031\n",
      "Epoch 31/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.9571 - accuracy: 0.5773 - val_loss: 0.9586 - val_accuracy: 0.5719\n",
      "Epoch 32/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.9521 - accuracy: 0.5789 - val_loss: 0.9568 - val_accuracy: 0.5656\n",
      "Epoch 33/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.9486 - accuracy: 0.5680 - val_loss: 0.9502 - val_accuracy: 0.5969\n",
      "Epoch 34/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.9442 - accuracy: 0.5789 - val_loss: 0.9479 - val_accuracy: 0.5250\n",
      "Epoch 35/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.9378 - accuracy: 0.5617 - val_loss: 0.9523 - val_accuracy: 0.5250\n",
      "Epoch 36/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.9344 - accuracy: 0.5555 - val_loss: 0.9566 - val_accuracy: 0.5656\n",
      "Epoch 37/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.9330 - accuracy: 0.5813 - val_loss: 0.9415 - val_accuracy: 0.6000\n",
      "Epoch 38/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.9272 - accuracy: 0.5898 - val_loss: 0.9321 - val_accuracy: 0.6031\n",
      "Epoch 39/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.9285 - accuracy: 0.5547 - val_loss: 0.9238 - val_accuracy: 0.5969\n",
      "Epoch 40/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.9214 - accuracy: 0.5789 - val_loss: 0.9267 - val_accuracy: 0.5719\n",
      "Epoch 41/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.9191 - accuracy: 0.5844 - val_loss: 0.9159 - val_accuracy: 0.5437\n",
      "Epoch 42/800\n",
      "1280/1280 [==============================] - ETA: 0s - loss: 0.9164 - accuracy: 0.60 - 2s 1ms/step - loss: 0.9177 - accuracy: 0.5992 - val_loss: 0.9146 - val_accuracy: 0.6062\n",
      "Epoch 43/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.9133 - accuracy: 0.5883 - val_loss: 0.9198 - val_accuracy: 0.5750\n",
      "Epoch 44/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.9076 - accuracy: 0.5844 - val_loss: 0.9056 - val_accuracy: 0.6125\n",
      "Epoch 45/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.9063 - accuracy: 0.5875 - val_loss: 0.9169 - val_accuracy: 0.5688\n",
      "Epoch 46/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.9044 - accuracy: 0.5930 - val_loss: 0.9088 - val_accuracy: 0.5719\n",
      "Epoch 47/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.9024 - accuracy: 0.5945 - val_loss: 0.9077 - val_accuracy: 0.5625\n",
      "Epoch 48/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.9027 - accuracy: 0.5914 - val_loss: 0.9000 - val_accuracy: 0.6031\n",
      "Epoch 49/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8986 - accuracy: 0.5766 - val_loss: 0.9046 - val_accuracy: 0.5625\n",
      "Epoch 50/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8939 - accuracy: 0.5930 - val_loss: 0.9004 - val_accuracy: 0.5875\n",
      "Epoch 51/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8939 - accuracy: 0.6102 - val_loss: 0.9018 - val_accuracy: 0.5531\n",
      "Epoch 52/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8908 - accuracy: 0.6102 - val_loss: 0.9250 - val_accuracy: 0.4781\n",
      "Epoch 53/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8921 - accuracy: 0.5789 - val_loss: 0.8862 - val_accuracy: 0.6031\n",
      "Epoch 54/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8834 - accuracy: 0.5969 - val_loss: 0.9079 - val_accuracy: 0.5500\n",
      "Epoch 55/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.8835 - accuracy: 0.5977 - val_loss: 0.8786 - val_accuracy: 0.6344\n",
      "Epoch 56/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.8832 - accuracy: 0.5953 - val_loss: 0.8759 - val_accuracy: 0.6344\n",
      "Epoch 57/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.8804 - accuracy: 0.5938 - val_loss: 0.8853 - val_accuracy: 0.6250\n",
      "Epoch 58/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.8793 - accuracy: 0.5891 - val_loss: 0.8835 - val_accuracy: 0.6000\n",
      "Epoch 59/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8745 - accuracy: 0.6055 - val_loss: 0.8762 - val_accuracy: 0.5844\n",
      "Epoch 60/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8723 - accuracy: 0.6008 - val_loss: 0.8753 - val_accuracy: 0.5750\n",
      "Epoch 61/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8729 - accuracy: 0.5992 - val_loss: 0.8758 - val_accuracy: 0.5906\n",
      "Epoch 62/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8715 - accuracy: 0.6102 - val_loss: 0.8773 - val_accuracy: 0.5844\n",
      "Epoch 63/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.8706 - accuracy: 0.5945 - val_loss: 0.8630 - val_accuracy: 0.5813\n",
      "Epoch 64/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.8683 - accuracy: 0.5773 - val_loss: 0.8733 - val_accuracy: 0.6031\n",
      "Epoch 65/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8650 - accuracy: 0.6070 - val_loss: 0.8586 - val_accuracy: 0.6062\n",
      "Epoch 66/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8630 - accuracy: 0.6195 - val_loss: 0.8593 - val_accuracy: 0.5781\n",
      "Epoch 67/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.8612 - accuracy: 0.6164 - val_loss: 0.8629 - val_accuracy: 0.6094\n",
      "Epoch 68/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8560 - accuracy: 0.6078 - val_loss: 0.8616 - val_accuracy: 0.5875\n",
      "Epoch 69/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8539 - accuracy: 0.6289 - val_loss: 0.8744 - val_accuracy: 0.5781\n",
      "Epoch 70/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8582 - accuracy: 0.6117 - val_loss: 0.8495 - val_accuracy: 0.6125\n",
      "Epoch 71/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8530 - accuracy: 0.6094 - val_loss: 0.8629 - val_accuracy: 0.5844\n",
      "Epoch 72/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8531 - accuracy: 0.6023 - val_loss: 0.8478 - val_accuracy: 0.6500\n",
      "Epoch 73/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8509 - accuracy: 0.6016 - val_loss: 0.8593 - val_accuracy: 0.6344\n",
      "Epoch 74/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8504 - accuracy: 0.6047 - val_loss: 0.8437 - val_accuracy: 0.6562\n",
      "Epoch 75/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8481 - accuracy: 0.6250 - val_loss: 0.8449 - val_accuracy: 0.6406\n",
      "Epoch 76/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8496 - accuracy: 0.6141 - val_loss: 0.8473 - val_accuracy: 0.6438\n",
      "Epoch 77/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8472 - accuracy: 0.6078 - val_loss: 0.8441 - val_accuracy: 0.5938\n",
      "Epoch 78/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8470 - accuracy: 0.6086 - val_loss: 0.8391 - val_accuracy: 0.6625\n",
      "Epoch 79/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8398 - accuracy: 0.6227 - val_loss: 0.8308 - val_accuracy: 0.6062\n",
      "Epoch 80/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8394 - accuracy: 0.6227 - val_loss: 0.8326 - val_accuracy: 0.6438\n",
      "Epoch 81/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8358 - accuracy: 0.6375 - val_loss: 0.8331 - val_accuracy: 0.6219\n",
      "Epoch 82/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.8396 - accuracy: 0.6133 - val_loss: 0.8279 - val_accuracy: 0.5844\n",
      "Epoch 83/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8390 - accuracy: 0.6211 - val_loss: 0.8279 - val_accuracy: 0.6156\n",
      "Epoch 84/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.8339 - accuracy: 0.6219 - val_loss: 0.8453 - val_accuracy: 0.5969\n",
      "Epoch 85/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8345 - accuracy: 0.6328 - val_loss: 0.8491 - val_accuracy: 0.5813\n",
      "Epoch 86/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8335 - accuracy: 0.6211 - val_loss: 0.8291 - val_accuracy: 0.6406\n",
      "Epoch 87/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8320 - accuracy: 0.6227 - val_loss: 0.8210 - val_accuracy: 0.6062\n",
      "Epoch 88/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8307 - accuracy: 0.6305 - val_loss: 0.8327 - val_accuracy: 0.6344\n",
      "Epoch 89/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8263 - accuracy: 0.6250 - val_loss: 0.8250 - val_accuracy: 0.6719\n",
      "Epoch 90/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8301 - accuracy: 0.6242 - val_loss: 0.8305 - val_accuracy: 0.5875\n",
      "Epoch 91/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8272 - accuracy: 0.6297 - val_loss: 0.8178 - val_accuracy: 0.6250\n",
      "Epoch 92/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8238 - accuracy: 0.6141 - val_loss: 0.8218 - val_accuracy: 0.6281\n",
      "Epoch 93/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.8240 - accuracy: 0.6187 - val_loss: 0.8138 - val_accuracy: 0.7031\n",
      "Epoch 94/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8230 - accuracy: 0.6281 - val_loss: 0.8194 - val_accuracy: 0.6906\n",
      "Epoch 95/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8191 - accuracy: 0.6328 - val_loss: 0.8095 - val_accuracy: 0.6594\n",
      "Epoch 96/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.8209 - accuracy: 0.6375 - val_loss: 0.8136 - val_accuracy: 0.6500\n",
      "Epoch 97/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8191 - accuracy: 0.6367 - val_loss: 0.8147 - val_accuracy: 0.6687\n",
      "Epoch 98/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8199 - accuracy: 0.6227 - val_loss: 0.8146 - val_accuracy: 0.6313\n",
      "Epoch 99/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8182 - accuracy: 0.6250 - val_loss: 0.8050 - val_accuracy: 0.6938\n",
      "Epoch 100/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8106 - accuracy: 0.6375 - val_loss: 0.8029 - val_accuracy: 0.6656\n",
      "Epoch 101/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8129 - accuracy: 0.6422 - val_loss: 0.8205 - val_accuracy: 0.5813\n",
      "Epoch 102/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8117 - accuracy: 0.6313 - val_loss: 0.8218 - val_accuracy: 0.5875\n",
      "Epoch 103/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8131 - accuracy: 0.6359 - val_loss: 0.8160 - val_accuracy: 0.6031\n",
      "Epoch 104/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8122 - accuracy: 0.6352 - val_loss: 0.8043 - val_accuracy: 0.5938\n",
      "Epoch 105/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8083 - accuracy: 0.6461 - val_loss: 0.7919 - val_accuracy: 0.6656\n",
      "Epoch 106/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8077 - accuracy: 0.6461 - val_loss: 0.8155 - val_accuracy: 0.6906\n",
      "Epoch 107/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8069 - accuracy: 0.6133 - val_loss: 0.7906 - val_accuracy: 0.7000\n",
      "Epoch 108/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8033 - accuracy: 0.6406 - val_loss: 0.8307 - val_accuracy: 0.6062\n",
      "Epoch 109/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8012 - accuracy: 0.6461 - val_loss: 0.8165 - val_accuracy: 0.6000\n",
      "Epoch 110/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8016 - accuracy: 0.6328 - val_loss: 0.7982 - val_accuracy: 0.6812\n",
      "Epoch 111/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7984 - accuracy: 0.6367 - val_loss: 0.7862 - val_accuracy: 0.6781\n",
      "Epoch 112/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7981 - accuracy: 0.6391 - val_loss: 0.8262 - val_accuracy: 0.5625\n",
      "Epoch 113/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.8011 - accuracy: 0.6398 - val_loss: 0.7950 - val_accuracy: 0.5938\n",
      "Epoch 114/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7994 - accuracy: 0.6328 - val_loss: 0.7843 - val_accuracy: 0.6250\n",
      "Epoch 115/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7992 - accuracy: 0.6570 - val_loss: 0.8045 - val_accuracy: 0.5875\n",
      "Epoch 116/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7986 - accuracy: 0.6445 - val_loss: 0.7875 - val_accuracy: 0.6969\n",
      "Epoch 117/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7961 - accuracy: 0.6547 - val_loss: 0.8082 - val_accuracy: 0.6344\n",
      "Epoch 118/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7923 - accuracy: 0.6492 - val_loss: 0.7864 - val_accuracy: 0.6906\n",
      "Epoch 119/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7963 - accuracy: 0.6445 - val_loss: 0.7815 - val_accuracy: 0.7031\n",
      "Epoch 120/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7960 - accuracy: 0.6445 - val_loss: 0.8001 - val_accuracy: 0.5813\n",
      "Epoch 121/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7919 - accuracy: 0.6477 - val_loss: 0.7942 - val_accuracy: 0.6719\n",
      "Epoch 122/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7921 - accuracy: 0.6391 - val_loss: 0.7845 - val_accuracy: 0.7063\n",
      "Epoch 123/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7884 - accuracy: 0.6461 - val_loss: 0.8009 - val_accuracy: 0.6125\n",
      "Epoch 124/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7915 - accuracy: 0.6586 - val_loss: 0.7862 - val_accuracy: 0.6500\n",
      "Epoch 125/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7890 - accuracy: 0.6398 - val_loss: 0.7811 - val_accuracy: 0.6000\n",
      "Epoch 126/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7862 - accuracy: 0.6547 - val_loss: 0.7672 - val_accuracy: 0.7094\n",
      "Epoch 127/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7876 - accuracy: 0.6477 - val_loss: 0.7770 - val_accuracy: 0.7063\n",
      "Epoch 128/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7852 - accuracy: 0.6711 - val_loss: 0.7874 - val_accuracy: 0.5938\n",
      "Epoch 129/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7824 - accuracy: 0.6641 - val_loss: 0.7764 - val_accuracy: 0.6406\n",
      "Epoch 130/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7772 - accuracy: 0.6539 - val_loss: 0.8104 - val_accuracy: 0.5813\n",
      "Epoch 131/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7861 - accuracy: 0.6398 - val_loss: 0.7717 - val_accuracy: 0.6531\n",
      "Epoch 132/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7774 - accuracy: 0.6570 - val_loss: 0.7621 - val_accuracy: 0.7469\n",
      "Epoch 133/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7760 - accuracy: 0.6562 - val_loss: 0.7649 - val_accuracy: 0.6187\n",
      "Epoch 134/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7815 - accuracy: 0.6617 - val_loss: 0.7634 - val_accuracy: 0.7375\n",
      "Epoch 135/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7770 - accuracy: 0.6734 - val_loss: 0.7982 - val_accuracy: 0.5688\n",
      "Epoch 136/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7790 - accuracy: 0.6711 - val_loss: 0.7542 - val_accuracy: 0.7031\n",
      "Epoch 137/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7730 - accuracy: 0.6531 - val_loss: 0.7574 - val_accuracy: 0.7188\n",
      "Epoch 138/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7745 - accuracy: 0.6633 - val_loss: 0.7598 - val_accuracy: 0.6250\n",
      "Epoch 139/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7753 - accuracy: 0.6836 - val_loss: 0.7582 - val_accuracy: 0.7406\n",
      "Epoch 140/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.7692 - accuracy: 0.6672 - val_loss: 0.7557 - val_accuracy: 0.6875\n",
      "Epoch 141/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.7723 - accuracy: 0.6617 - val_loss: 0.7709 - val_accuracy: 0.6406\n",
      "Epoch 142/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7681 - accuracy: 0.6609 - val_loss: 0.7642 - val_accuracy: 0.7250\n",
      "Epoch 143/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7661 - accuracy: 0.6758 - val_loss: 0.7544 - val_accuracy: 0.6125\n",
      "Epoch 144/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7679 - accuracy: 0.6789 - val_loss: 0.7825 - val_accuracy: 0.6031\n",
      "Epoch 145/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7672 - accuracy: 0.6617 - val_loss: 0.7504 - val_accuracy: 0.7063\n",
      "Epoch 146/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7639 - accuracy: 0.6672 - val_loss: 0.7576 - val_accuracy: 0.6281\n",
      "Epoch 147/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7648 - accuracy: 0.6695 - val_loss: 0.7491 - val_accuracy: 0.7031\n",
      "Epoch 148/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7657 - accuracy: 0.6742 - val_loss: 0.7541 - val_accuracy: 0.6125\n",
      "Epoch 149/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7578 - accuracy: 0.6562 - val_loss: 0.7770 - val_accuracy: 0.7312\n",
      "Epoch 150/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7692 - accuracy: 0.6711 - val_loss: 0.7422 - val_accuracy: 0.7563\n",
      "Epoch 151/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7617 - accuracy: 0.6680 - val_loss: 0.7555 - val_accuracy: 0.6000\n",
      "Epoch 152/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7641 - accuracy: 0.6602 - val_loss: 0.7467 - val_accuracy: 0.7344\n",
      "Epoch 153/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7628 - accuracy: 0.6703 - val_loss: 0.7592 - val_accuracy: 0.7063\n",
      "Epoch 154/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7558 - accuracy: 0.6711 - val_loss: 0.7554 - val_accuracy: 0.6219\n",
      "Epoch 155/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7610 - accuracy: 0.6680 - val_loss: 0.7364 - val_accuracy: 0.7000\n",
      "Epoch 156/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7562 - accuracy: 0.6891 - val_loss: 0.7362 - val_accuracy: 0.7563\n",
      "Epoch 157/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7593 - accuracy: 0.6812 - val_loss: 0.7347 - val_accuracy: 0.6906\n",
      "Epoch 158/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7504 - accuracy: 0.6805 - val_loss: 0.7699 - val_accuracy: 0.6531\n",
      "Epoch 159/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7554 - accuracy: 0.6687 - val_loss: 0.7501 - val_accuracy: 0.6219\n",
      "Epoch 160/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7538 - accuracy: 0.7016 - val_loss: 0.7329 - val_accuracy: 0.7031\n",
      "Epoch 161/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7542 - accuracy: 0.6781 - val_loss: 0.7427 - val_accuracy: 0.6562\n",
      "Epoch 162/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7474 - accuracy: 0.6844 - val_loss: 0.7326 - val_accuracy: 0.8125\n",
      "Epoch 163/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7472 - accuracy: 0.6875 - val_loss: 0.7453 - val_accuracy: 0.6062\n",
      "Epoch 164/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7490 - accuracy: 0.6961 - val_loss: 0.7379 - val_accuracy: 0.7500\n",
      "Epoch 165/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7464 - accuracy: 0.6922 - val_loss: 0.7273 - val_accuracy: 0.7281\n",
      "Epoch 166/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7455 - accuracy: 0.7070 - val_loss: 0.7307 - val_accuracy: 0.6313\n",
      "Epoch 167/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7443 - accuracy: 0.6805 - val_loss: 0.7198 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7418 - accuracy: 0.7117 - val_loss: 0.7217 - val_accuracy: 0.7312\n",
      "Epoch 169/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7441 - accuracy: 0.7055 - val_loss: 0.7251 - val_accuracy: 0.6969\n",
      "Epoch 170/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7388 - accuracy: 0.6992 - val_loss: 0.7251 - val_accuracy: 0.6438\n",
      "Epoch 171/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7391 - accuracy: 0.6914 - val_loss: 0.7542 - val_accuracy: 0.7031\n",
      "Epoch 172/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7407 - accuracy: 0.7078 - val_loss: 0.7213 - val_accuracy: 0.6313\n",
      "Epoch 173/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7407 - accuracy: 0.7086 - val_loss: 0.7147 - val_accuracy: 0.7250\n",
      "Epoch 174/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7424 - accuracy: 0.6938 - val_loss: 0.7275 - val_accuracy: 0.6281\n",
      "Epoch 175/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7381 - accuracy: 0.6766 - val_loss: 0.7245 - val_accuracy: 0.7719\n",
      "Epoch 176/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7369 - accuracy: 0.6969 - val_loss: 0.7164 - val_accuracy: 0.7969\n",
      "Epoch 177/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7343 - accuracy: 0.6914 - val_loss: 0.7222 - val_accuracy: 0.7594\n",
      "Epoch 178/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7299 - accuracy: 0.6930 - val_loss: 0.7733 - val_accuracy: 0.5719\n",
      "Epoch 179/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7342 - accuracy: 0.6914 - val_loss: 0.7261 - val_accuracy: 0.7500\n",
      "Epoch 180/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7353 - accuracy: 0.7070 - val_loss: 0.7405 - val_accuracy: 0.6344\n",
      "Epoch 181/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7253 - accuracy: 0.6922 - val_loss: 0.7034 - val_accuracy: 0.7531\n",
      "Epoch 182/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7279 - accuracy: 0.7078 - val_loss: 0.7193 - val_accuracy: 0.7219\n",
      "Epoch 183/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7292 - accuracy: 0.7141 - val_loss: 0.7016 - val_accuracy: 0.8062\n",
      "Epoch 184/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7280 - accuracy: 0.7102 - val_loss: 0.7049 - val_accuracy: 0.7781\n",
      "Epoch 185/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7311 - accuracy: 0.7133 - val_loss: 0.7097 - val_accuracy: 0.7688\n",
      "Epoch 186/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.7148 - val_loss: 0.7051 - val_accuracy: 0.6469\n",
      "Epoch 187/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7203 - accuracy: 0.7289 - val_loss: 0.7251 - val_accuracy: 0.6250\n",
      "Epoch 188/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7236 - accuracy: 0.7156 - val_loss: 0.7007 - val_accuracy: 0.6562\n",
      "Epoch 189/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7247 - accuracy: 0.7125 - val_loss: 0.7041 - val_accuracy: 0.8094\n",
      "Epoch 190/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7221 - accuracy: 0.7008 - val_loss: 0.6947 - val_accuracy: 0.7625\n",
      "Epoch 191/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7194 - accuracy: 0.7195 - val_loss: 0.7284 - val_accuracy: 0.6875\n",
      "Epoch 192/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7113 - accuracy: 0.7133 - val_loss: 0.6942 - val_accuracy: 0.7969\n",
      "Epoch 193/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7141 - accuracy: 0.7172 - val_loss: 0.7009 - val_accuracy: 0.7750\n",
      "Epoch 194/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7191 - accuracy: 0.7117 - val_loss: 0.7022 - val_accuracy: 0.6500\n",
      "Epoch 195/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.7173 - accuracy: 0.7203 - val_loss: 0.7175 - val_accuracy: 0.6625\n",
      "Epoch 196/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.7150 - accuracy: 0.7086 - val_loss: 0.6885 - val_accuracy: 0.7906\n",
      "Epoch 197/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.7127 - accuracy: 0.7258 - val_loss: 0.7223 - val_accuracy: 0.7281\n",
      "Epoch 198/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.7108 - accuracy: 0.7234 - val_loss: 0.7299 - val_accuracy: 0.5969\n",
      "Epoch 199/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.7165 - accuracy: 0.7008 - val_loss: 0.6910 - val_accuracy: 0.7375\n",
      "Epoch 200/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.7120 - accuracy: 0.7156 - val_loss: 0.6963 - val_accuracy: 0.7219\n",
      "Epoch 201/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.7095 - accuracy: 0.7063 - val_loss: 0.7031 - val_accuracy: 0.6875\n",
      "Epoch 202/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.7065 - accuracy: 0.7109 - val_loss: 0.7114 - val_accuracy: 0.6625\n",
      "Epoch 203/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.7091 - accuracy: 0.7273 - val_loss: 0.6804 - val_accuracy: 0.7875\n",
      "Epoch 204/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.7045 - accuracy: 0.7117 - val_loss: 0.7020 - val_accuracy: 0.6687\n",
      "Epoch 205/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.7043 - accuracy: 0.7188 - val_loss: 0.7207 - val_accuracy: 0.5875\n",
      "Epoch 206/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.7068 - accuracy: 0.7133 - val_loss: 0.6830 - val_accuracy: 0.6687\n",
      "Epoch 207/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6984 - accuracy: 0.7250 - val_loss: 0.6780 - val_accuracy: 0.7719\n",
      "Epoch 208/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.7043 - accuracy: 0.7383 - val_loss: 0.6838 - val_accuracy: 0.7812\n",
      "Epoch 209/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.7040 - accuracy: 0.7289 - val_loss: 0.6728 - val_accuracy: 0.8344\n",
      "Epoch 210/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6993 - accuracy: 0.7453 - val_loss: 0.6731 - val_accuracy: 0.7437\n",
      "Epoch 211/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.7022 - accuracy: 0.7305 - val_loss: 0.7002 - val_accuracy: 0.6687\n",
      "Epoch 212/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.7013 - accuracy: 0.7344 - val_loss: 0.6951 - val_accuracy: 0.6531\n",
      "Epoch 213/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6995 - accuracy: 0.7250 - val_loss: 0.6795 - val_accuracy: 0.8219\n",
      "Epoch 214/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6973 - accuracy: 0.7289 - val_loss: 0.6760 - val_accuracy: 0.7094\n",
      "Epoch 215/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6968 - accuracy: 0.7258 - val_loss: 0.6667 - val_accuracy: 0.8250\n",
      "Epoch 216/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6942 - accuracy: 0.7312 - val_loss: 0.6679 - val_accuracy: 0.7875\n",
      "Epoch 217/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6981 - accuracy: 0.7234 - val_loss: 0.6658 - val_accuracy: 0.8188\n",
      "Epoch 218/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6898 - accuracy: 0.7539 - val_loss: 0.6725 - val_accuracy: 0.7188\n",
      "Epoch 219/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6926 - accuracy: 0.7258 - val_loss: 0.6750 - val_accuracy: 0.7250\n",
      "Epoch 220/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.6874 - accuracy: 0.7336 - val_loss: 0.6734 - val_accuracy: 0.7000\n",
      "Epoch 221/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6944 - accuracy: 0.7414 - val_loss: 0.6619 - val_accuracy: 0.7500\n",
      "Epoch 222/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6878 - accuracy: 0.7617 - val_loss: 0.6956 - val_accuracy: 0.7656\n",
      "Epoch 223/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.6903 - accuracy: 0.7344 - val_loss: 0.6625 - val_accuracy: 0.8281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.6837 - accuracy: 0.7664 - val_loss: 0.7415 - val_accuracy: 0.6469\n",
      "Epoch 225/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.6877 - accuracy: 0.7461 - val_loss: 0.6708 - val_accuracy: 0.7000\n",
      "Epoch 226/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6788 - accuracy: 0.7383 - val_loss: 0.7073 - val_accuracy: 0.6500\n",
      "Epoch 227/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.7461 - val_loss: 0.6622 - val_accuracy: 0.7125\n",
      "Epoch 228/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.6838 - accuracy: 0.7508 - val_loss: 0.6674 - val_accuracy: 0.6969\n",
      "Epoch 229/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.6809 - accuracy: 0.7414 - val_loss: 0.6887 - val_accuracy: 0.6531\n",
      "Epoch 230/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.6776 - accuracy: 0.7422 - val_loss: 0.7070 - val_accuracy: 0.6875\n",
      "Epoch 231/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6792 - accuracy: 0.7406 - val_loss: 0.6513 - val_accuracy: 0.8406\n",
      "Epoch 232/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6770 - accuracy: 0.7570 - val_loss: 0.6593 - val_accuracy: 0.8000\n",
      "Epoch 233/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6815 - accuracy: 0.7523 - val_loss: 0.6713 - val_accuracy: 0.7688\n",
      "Epoch 234/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6731 - accuracy: 0.7375 - val_loss: 0.7239 - val_accuracy: 0.6062\n",
      "Epoch 235/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6747 - accuracy: 0.7680 - val_loss: 0.6423 - val_accuracy: 0.8531\n",
      "Epoch 236/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6735 - accuracy: 0.7563 - val_loss: 0.6663 - val_accuracy: 0.7031\n",
      "Epoch 237/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6726 - accuracy: 0.7633 - val_loss: 0.6528 - val_accuracy: 0.8125\n",
      "Epoch 238/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6688 - accuracy: 0.7531 - val_loss: 0.6456 - val_accuracy: 0.8438\n",
      "Epoch 239/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6628 - accuracy: 0.7484 - val_loss: 0.6653 - val_accuracy: 0.7531\n",
      "Epoch 240/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6693 - accuracy: 0.7437 - val_loss: 0.6391 - val_accuracy: 0.8156\n",
      "Epoch 241/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6701 - accuracy: 0.7555 - val_loss: 0.6397 - val_accuracy: 0.7563\n",
      "Epoch 242/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6611 - accuracy: 0.7500 - val_loss: 0.6489 - val_accuracy: 0.6938\n",
      "Epoch 243/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6587 - accuracy: 0.7594 - val_loss: 0.6394 - val_accuracy: 0.7781\n",
      "Epoch 244/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.6542 - accuracy: 0.7523 - val_loss: 0.6343 - val_accuracy: 0.8188\n",
      "Epoch 245/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6617 - accuracy: 0.7602 - val_loss: 0.6311 - val_accuracy: 0.8344\n",
      "Epoch 246/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.6635 - accuracy: 0.7523 - val_loss: 0.6278 - val_accuracy: 0.8531\n",
      "Epoch 247/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6656 - accuracy: 0.7469 - val_loss: 0.6416 - val_accuracy: 0.7750\n",
      "Epoch 248/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.6562 - accuracy: 0.7578 - val_loss: 0.6374 - val_accuracy: 0.8219\n",
      "Epoch 249/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.7602 - val_loss: 0.6409 - val_accuracy: 0.8156\n",
      "Epoch 250/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.6558 - accuracy: 0.7656 - val_loss: 0.6596 - val_accuracy: 0.7812\n",
      "Epoch 251/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.6586 - accuracy: 0.7609 - val_loss: 0.6599 - val_accuracy: 0.7844\n",
      "Epoch 252/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.6638 - accuracy: 0.7570 - val_loss: 0.6343 - val_accuracy: 0.8531\n",
      "Epoch 253/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6506 - accuracy: 0.7703 - val_loss: 0.7046 - val_accuracy: 0.7094\n",
      "Epoch 254/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.6501 - accuracy: 0.7617 - val_loss: 0.6242 - val_accuracy: 0.8406\n",
      "Epoch 255/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6554 - accuracy: 0.7656 - val_loss: 0.6218 - val_accuracy: 0.8562\n",
      "Epoch 256/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.6445 - accuracy: 0.7688 - val_loss: 0.6288 - val_accuracy: 0.8406\n",
      "Epoch 257/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.6470 - accuracy: 0.7617 - val_loss: 0.6482 - val_accuracy: 0.6875\n",
      "Epoch 258/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6529 - accuracy: 0.7594 - val_loss: 0.6229 - val_accuracy: 0.8281\n",
      "Epoch 259/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6478 - accuracy: 0.7688 - val_loss: 0.6540 - val_accuracy: 0.8219\n",
      "Epoch 260/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6385 - accuracy: 0.7742 - val_loss: 0.6693 - val_accuracy: 0.6594\n",
      "Epoch 261/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.6469 - accuracy: 0.7891 - val_loss: 0.6179 - val_accuracy: 0.8562\n",
      "Epoch 262/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6407 - accuracy: 0.7805 - val_loss: 0.6113 - val_accuracy: 0.8531\n",
      "Epoch 263/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.6510 - accuracy: 0.7789 - val_loss: 0.6570 - val_accuracy: 0.6187\n",
      "Epoch 264/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6430 - accuracy: 0.7633 - val_loss: 0.6069 - val_accuracy: 0.8562\n",
      "Epoch 265/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6479 - accuracy: 0.7641 - val_loss: 0.6217 - val_accuracy: 0.7531\n",
      "Epoch 266/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.6337 - accuracy: 0.7734 - val_loss: 0.6725 - val_accuracy: 0.7156\n",
      "Epoch 267/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.6381 - accuracy: 0.7609 - val_loss: 0.6017 - val_accuracy: 0.8500\n",
      "Epoch 268/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6353 - accuracy: 0.7719 - val_loss: 0.6080 - val_accuracy: 0.8625\n",
      "Epoch 269/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6376 - accuracy: 0.7656 - val_loss: 0.6513 - val_accuracy: 0.6906\n",
      "Epoch 270/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6349 - accuracy: 0.7883 - val_loss: 0.6066 - val_accuracy: 0.8281\n",
      "Epoch 271/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6339 - accuracy: 0.7719 - val_loss: 0.6930 - val_accuracy: 0.6313\n",
      "Epoch 272/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6355 - accuracy: 0.7734 - val_loss: 0.6268 - val_accuracy: 0.7719\n",
      "Epoch 273/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6310 - accuracy: 0.7828 - val_loss: 0.6018 - val_accuracy: 0.8094\n",
      "Epoch 274/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6357 - accuracy: 0.7711 - val_loss: 0.6124 - val_accuracy: 0.7906\n",
      "Epoch 275/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6242 - accuracy: 0.7812 - val_loss: 0.6102 - val_accuracy: 0.8469\n",
      "Epoch 276/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6341 - accuracy: 0.7750 - val_loss: 0.5936 - val_accuracy: 0.8594\n",
      "Epoch 277/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6273 - accuracy: 0.7688 - val_loss: 0.5936 - val_accuracy: 0.8406\n",
      "Epoch 278/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6267 - accuracy: 0.7734 - val_loss: 0.5998 - val_accuracy: 0.8156\n",
      "Epoch 279/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6266 - accuracy: 0.7789 - val_loss: 0.5975 - val_accuracy: 0.8625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6216 - accuracy: 0.7820 - val_loss: 0.5890 - val_accuracy: 0.8406\n",
      "Epoch 281/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6178 - accuracy: 0.7875 - val_loss: 0.5945 - val_accuracy: 0.8687\n",
      "Epoch 282/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6284 - accuracy: 0.7781 - val_loss: 0.5995 - val_accuracy: 0.8188\n",
      "Epoch 283/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6259 - accuracy: 0.7844 - val_loss: 0.6501 - val_accuracy: 0.6844\n",
      "Epoch 284/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6213 - accuracy: 0.7781 - val_loss: 0.5812 - val_accuracy: 0.8719\n",
      "Epoch 285/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6247 - accuracy: 0.7914 - val_loss: 0.6632 - val_accuracy: 0.5875\n",
      "Epoch 286/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6086 - accuracy: 0.7906 - val_loss: 0.6043 - val_accuracy: 0.7219\n",
      "Epoch 287/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6063 - accuracy: 0.7953 - val_loss: 0.5737 - val_accuracy: 0.8594\n",
      "Epoch 288/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6179 - accuracy: 0.7883 - val_loss: 0.5846 - val_accuracy: 0.8344\n",
      "Epoch 289/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6153 - accuracy: 0.7875 - val_loss: 0.6030 - val_accuracy: 0.7844\n",
      "Epoch 290/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6072 - accuracy: 0.7820 - val_loss: 0.6014 - val_accuracy: 0.6875\n",
      "Epoch 291/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6073 - accuracy: 0.7984 - val_loss: 0.5820 - val_accuracy: 0.7937\n",
      "Epoch 292/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6018 - accuracy: 0.8000 - val_loss: 0.5816 - val_accuracy: 0.8281\n",
      "Epoch 293/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6174 - accuracy: 0.7695 - val_loss: 0.5887 - val_accuracy: 0.8594\n",
      "Epoch 294/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6087 - accuracy: 0.7961 - val_loss: 0.5822 - val_accuracy: 0.8344\n",
      "Epoch 295/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6042 - accuracy: 0.7859 - val_loss: 0.5710 - val_accuracy: 0.8438\n",
      "Epoch 296/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6030 - accuracy: 0.7883 - val_loss: 0.5795 - val_accuracy: 0.8750\n",
      "Epoch 297/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6048 - accuracy: 0.7906 - val_loss: 0.5646 - val_accuracy: 0.8656\n",
      "Epoch 298/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6037 - accuracy: 0.7781 - val_loss: 0.5898 - val_accuracy: 0.7844\n",
      "Epoch 299/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.6065 - accuracy: 0.7891 - val_loss: 0.5760 - val_accuracy: 0.8125\n",
      "Epoch 300/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5936 - accuracy: 0.7906 - val_loss: 0.5886 - val_accuracy: 0.7594\n",
      "Epoch 301/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5941 - accuracy: 0.8016 - val_loss: 0.5670 - val_accuracy: 0.8531\n",
      "Epoch 302/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5922 - accuracy: 0.7883 - val_loss: 0.5867 - val_accuracy: 0.8406\n",
      "Epoch 303/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5987 - accuracy: 0.7883 - val_loss: 0.5851 - val_accuracy: 0.8687\n",
      "Epoch 304/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5970 - accuracy: 0.7937 - val_loss: 0.5576 - val_accuracy: 0.8656\n",
      "Epoch 305/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5920 - accuracy: 0.8070 - val_loss: 0.5480 - val_accuracy: 0.8906\n",
      "Epoch 306/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5877 - accuracy: 0.7922 - val_loss: 0.5543 - val_accuracy: 0.8625\n",
      "Epoch 307/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5956 - accuracy: 0.8133 - val_loss: 0.5678 - val_accuracy: 0.8687\n",
      "Epoch 308/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5901 - accuracy: 0.7961 - val_loss: 0.5719 - val_accuracy: 0.8313\n",
      "Epoch 309/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5823 - accuracy: 0.8008 - val_loss: 0.5939 - val_accuracy: 0.7531\n",
      "Epoch 310/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5863 - accuracy: 0.8047 - val_loss: 0.5447 - val_accuracy: 0.8750\n",
      "Epoch 311/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5856 - accuracy: 0.7977 - val_loss: 0.5694 - val_accuracy: 0.8031\n",
      "Epoch 312/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.5880 - accuracy: 0.8070 - val_loss: 0.5414 - val_accuracy: 0.8781\n",
      "Epoch 313/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5779 - accuracy: 0.8031 - val_loss: 0.5819 - val_accuracy: 0.8313\n",
      "Epoch 314/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5814 - accuracy: 0.7953 - val_loss: 0.5637 - val_accuracy: 0.8031\n",
      "Epoch 315/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5761 - accuracy: 0.8203 - val_loss: 0.5676 - val_accuracy: 0.7375\n",
      "Epoch 316/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5902 - accuracy: 0.7805 - val_loss: 0.5717 - val_accuracy: 0.7875\n",
      "Epoch 317/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5836 - accuracy: 0.7945 - val_loss: 0.5980 - val_accuracy: 0.6812\n",
      "Epoch 318/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5790 - accuracy: 0.7984 - val_loss: 0.5364 - val_accuracy: 0.8719\n",
      "Epoch 319/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5715 - accuracy: 0.7969 - val_loss: 0.5698 - val_accuracy: 0.7875\n",
      "Epoch 320/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5804 - accuracy: 0.7844 - val_loss: 0.5387 - val_accuracy: 0.8469\n",
      "Epoch 321/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5717 - accuracy: 0.8117 - val_loss: 0.5334 - val_accuracy: 0.8594\n",
      "Epoch 322/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5745 - accuracy: 0.7969 - val_loss: 0.5334 - val_accuracy: 0.8750\n",
      "Epoch 323/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5643 - accuracy: 0.8234 - val_loss: 0.5350 - val_accuracy: 0.8406\n",
      "Epoch 324/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5699 - accuracy: 0.8031 - val_loss: 0.5590 - val_accuracy: 0.8000\n",
      "Epoch 325/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5703 - accuracy: 0.8023 - val_loss: 0.5370 - val_accuracy: 0.8375\n",
      "Epoch 326/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5733 - accuracy: 0.7992 - val_loss: 0.5279 - val_accuracy: 0.8875\n",
      "Epoch 327/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5819 - accuracy: 0.7820 - val_loss: 0.5180 - val_accuracy: 0.8656\n",
      "Epoch 328/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5654 - accuracy: 0.8039 - val_loss: 0.5340 - val_accuracy: 0.8375\n",
      "Epoch 329/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5650 - accuracy: 0.8219 - val_loss: 0.5253 - val_accuracy: 0.8625\n",
      "Epoch 330/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5654 - accuracy: 0.7969 - val_loss: 0.5168 - val_accuracy: 0.8625\n",
      "Epoch 331/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5725 - accuracy: 0.8023 - val_loss: 0.5635 - val_accuracy: 0.7937\n",
      "Epoch 332/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5539 - accuracy: 0.8133 - val_loss: 0.5835 - val_accuracy: 0.7844\n",
      "Epoch 333/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5625 - accuracy: 0.8055 - val_loss: 0.5616 - val_accuracy: 0.8000\n",
      "Epoch 334/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5572 - accuracy: 0.8172 - val_loss: 0.5448 - val_accuracy: 0.7812\n",
      "Epoch 335/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5540 - accuracy: 0.7984 - val_loss: 0.5259 - val_accuracy: 0.8438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5563 - accuracy: 0.8227 - val_loss: 0.5649 - val_accuracy: 0.7750\n",
      "Epoch 337/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5628 - accuracy: 0.8062 - val_loss: 0.5128 - val_accuracy: 0.8594\n",
      "Epoch 338/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5667 - accuracy: 0.7984 - val_loss: 0.5272 - val_accuracy: 0.8781\n",
      "Epoch 339/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5519 - accuracy: 0.8227 - val_loss: 0.5726 - val_accuracy: 0.6687\n",
      "Epoch 340/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5479 - accuracy: 0.8125 - val_loss: 0.5500 - val_accuracy: 0.7781\n",
      "Epoch 341/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5524 - accuracy: 0.8109 - val_loss: 0.5135 - val_accuracy: 0.8781\n",
      "Epoch 342/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5356 - accuracy: 0.8227 - val_loss: 0.5397 - val_accuracy: 0.7969\n",
      "Epoch 343/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5534 - accuracy: 0.8023 - val_loss: 0.5201 - val_accuracy: 0.8500\n",
      "Epoch 344/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5480 - accuracy: 0.8070 - val_loss: 0.5167 - val_accuracy: 0.8687\n",
      "Epoch 345/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.8117 - val_loss: 0.5106 - val_accuracy: 0.8813\n",
      "Epoch 346/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5505 - accuracy: 0.8023 - val_loss: 0.5235 - val_accuracy: 0.8281\n",
      "Epoch 347/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5434 - accuracy: 0.8125 - val_loss: 0.5066 - val_accuracy: 0.8406\n",
      "Epoch 348/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5413 - accuracy: 0.8250 - val_loss: 0.5072 - val_accuracy: 0.8750\n",
      "Epoch 349/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5492 - accuracy: 0.8055 - val_loss: 0.5411 - val_accuracy: 0.7875\n",
      "Epoch 350/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5391 - accuracy: 0.8164 - val_loss: 0.5052 - val_accuracy: 0.8687\n",
      "Epoch 351/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.8258 - val_loss: 0.5259 - val_accuracy: 0.8188s: 0.5214 - accuracy - ETA: 0s - los\n",
      "Epoch 352/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.8078 - val_loss: 0.5259 - val_accuracy: 0.8656\n",
      "Epoch 353/800\n",
      "1280/1280 [==============================] - 3s 2ms/step - loss: 0.5302 - accuracy: 0.8273 - val_loss: 0.4995 - val_accuracy: 0.8750\n",
      "Epoch 354/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5416 - accuracy: 0.8156 - val_loss: 0.5916 - val_accuracy: 0.6250\n",
      "Epoch 355/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5331 - accuracy: 0.8188 - val_loss: 0.5150 - val_accuracy: 0.8687: 0s - loss: 0.5379 - accu\n",
      "Epoch 356/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5381 - accuracy: 0.8125 - val_loss: 0.4832 - val_accuracy: 0.8750\n",
      "Epoch 357/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5229 - accuracy: 0.8289 - val_loss: 0.5074 - val_accuracy: 0.8125\n",
      "Epoch 358/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5210 - accuracy: 0.8281 - val_loss: 0.4986 - val_accuracy: 0.8469\n",
      "Epoch 359/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5271 - accuracy: 0.8219 - val_loss: 0.6528 - val_accuracy: 0.6875\n",
      "Epoch 360/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5372 - accuracy: 0.8273 - val_loss: 0.5307 - val_accuracy: 0.7906\n",
      "Epoch 361/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5291 - accuracy: 0.8195 - val_loss: 0.4997 - val_accuracy: 0.8406\n",
      "Epoch 362/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5204 - accuracy: 0.8250 - val_loss: 0.5844 - val_accuracy: 0.7375\n",
      "Epoch 363/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5183 - accuracy: 0.8352 - val_loss: 0.5160 - val_accuracy: 0.8062\n",
      "Epoch 364/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5119 - accuracy: 0.8375 - val_loss: 0.5246 - val_accuracy: 0.8562\n",
      "Epoch 365/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5167 - accuracy: 0.8375 - val_loss: 0.5270 - val_accuracy: 0.7937\n",
      "Epoch 366/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5359 - accuracy: 0.8148 - val_loss: 0.5363 - val_accuracy: 0.7281\n",
      "Epoch 367/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5138 - accuracy: 0.8180 - val_loss: 0.4802 - val_accuracy: 0.8656\n",
      "Epoch 368/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5061 - accuracy: 0.8445 - val_loss: 0.4890 - val_accuracy: 0.8750\n",
      "Epoch 369/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5245 - accuracy: 0.8234 - val_loss: 0.5207 - val_accuracy: 0.7719\n",
      "Epoch 370/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5150 - accuracy: 0.8266 - val_loss: 0.5780 - val_accuracy: 0.6406\n",
      "Epoch 371/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5118 - accuracy: 0.8328 - val_loss: 0.5523 - val_accuracy: 0.7375\n",
      "Epoch 372/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5194 - accuracy: 0.8117 - val_loss: 0.4711 - val_accuracy: 0.8656\n",
      "Epoch 373/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5337 - accuracy: 0.8062 - val_loss: 0.6236 - val_accuracy: 0.6969\n",
      "Epoch 374/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5179 - accuracy: 0.8227 - val_loss: 0.5034 - val_accuracy: 0.8156\n",
      "Epoch 375/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5231 - accuracy: 0.8078 - val_loss: 0.4778 - val_accuracy: 0.8438\n",
      "Epoch 376/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5063 - accuracy: 0.8422 - val_loss: 0.4629 - val_accuracy: 0.9000\n",
      "Epoch 377/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5087 - accuracy: 0.8297 - val_loss: 0.4661 - val_accuracy: 0.8813\n",
      "Epoch 378/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5078 - accuracy: 0.8359 - val_loss: 0.4667 - val_accuracy: 0.8531\n",
      "Epoch 379/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4991 - accuracy: 0.8383 - val_loss: 0.4524 - val_accuracy: 0.8750\n",
      "Epoch 380/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5015 - accuracy: 0.8469 - val_loss: 0.5337 - val_accuracy: 0.7625\n",
      "Epoch 381/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4956 - accuracy: 0.8422 - val_loss: 0.4591 - val_accuracy: 0.8813\n",
      "Epoch 382/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5082 - accuracy: 0.8313 - val_loss: 0.4766 - val_accuracy: 0.8844\n",
      "Epoch 383/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4924 - accuracy: 0.8391 - val_loss: 0.4859 - val_accuracy: 0.8813\n",
      "Epoch 384/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4977 - accuracy: 0.8273 - val_loss: 0.5124 - val_accuracy: 0.8031\n",
      "Epoch 385/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5074 - accuracy: 0.8227 - val_loss: 0.5932 - val_accuracy: 0.6719\n",
      "Epoch 386/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4861 - accuracy: 0.8367 - val_loss: 0.5458 - val_accuracy: 0.7750\n",
      "Epoch 387/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5068 - accuracy: 0.8180 - val_loss: 0.4706 - val_accuracy: 0.8719\n",
      "Epoch 388/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5005 - accuracy: 0.8219 - val_loss: 0.4588 - val_accuracy: 0.8750\n",
      "Epoch 389/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5131 - accuracy: 0.8070 - val_loss: 0.5193 - val_accuracy: 0.7812\n",
      "Epoch 390/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4860 - accuracy: 0.8445 - val_loss: 0.4401 - val_accuracy: 0.9094\n",
      "Epoch 391/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5023 - accuracy: 0.8313 - val_loss: 0.4492 - val_accuracy: 0.8906\n",
      "Epoch 392/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.5039 - accuracy: 0.8242 - val_loss: 0.4359 - val_accuracy: 0.9125\n",
      "Epoch 393/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4982 - accuracy: 0.8273 - val_loss: 0.4474 - val_accuracy: 0.8844\n",
      "Epoch 394/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4993 - accuracy: 0.8242 - val_loss: 0.4549 - val_accuracy: 0.8781\n",
      "Epoch 395/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4865 - accuracy: 0.8336 - val_loss: 0.4405 - val_accuracy: 0.8781\n",
      "Epoch 396/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4970 - accuracy: 0.8297 - val_loss: 0.4438 - val_accuracy: 0.8875\n",
      "Epoch 397/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4798 - accuracy: 0.8414 - val_loss: 0.5106 - val_accuracy: 0.7875\n",
      "Epoch 398/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5180 - accuracy: 0.8062 - val_loss: 0.5030 - val_accuracy: 0.8281\n",
      "Epoch 399/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5017 - accuracy: 0.8242 - val_loss: 0.4317 - val_accuracy: 0.9094\n",
      "Epoch 400/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4882 - accuracy: 0.8430 - val_loss: 0.4343 - val_accuracy: 0.8750\n",
      "Epoch 401/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4671 - accuracy: 0.8445 - val_loss: 0.4464 - val_accuracy: 0.8687: 0.84\n",
      "Epoch 402/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4792 - accuracy: 0.8336 - val_loss: 0.4300 - val_accuracy: 0.8938\n",
      "Epoch 403/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4880 - accuracy: 0.8477 - val_loss: 0.5397 - val_accuracy: 0.6594\n",
      "Epoch 404/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4881 - accuracy: 0.8250 - val_loss: 0.4301 - val_accuracy: 0.8813\n",
      "Epoch 405/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4863 - accuracy: 0.8266 - val_loss: 0.5237 - val_accuracy: 0.7656\n",
      "Epoch 406/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4987 - accuracy: 0.8234 - val_loss: 0.4783 - val_accuracy: 0.8094\n",
      "Epoch 407/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4635 - accuracy: 0.8492 - val_loss: 0.5545 - val_accuracy: 0.6781\n",
      "Epoch 408/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4871 - accuracy: 0.8320 - val_loss: 0.4299 - val_accuracy: 0.8750\n",
      "Epoch 409/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4732 - accuracy: 0.8414 - val_loss: 0.4471 - val_accuracy: 0.8844\n",
      "Epoch 410/800\n",
      "1280/1280 [==============================] - ETA: 0s - loss: 0.4773 - accuracy: 0.83 - 2s 1ms/step - loss: 0.4755 - accuracy: 0.8320 - val_loss: 0.4634 - val_accuracy: 0.8281\n",
      "Epoch 411/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5053 - accuracy: 0.8117 - val_loss: 0.4258 - val_accuracy: 0.8813\n",
      "Epoch 412/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4703 - accuracy: 0.8391 - val_loss: 1.0432 - val_accuracy: 0.5562\n",
      "Epoch 413/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.4857 - accuracy: 0.8242 - val_loss: 0.4371 - val_accuracy: 0.8562\n",
      "Epoch 414/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4789 - accuracy: 0.8383 - val_loss: 0.4862 - val_accuracy: 0.7844\n",
      "Epoch 415/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4668 - accuracy: 0.8406 - val_loss: 0.4213 - val_accuracy: 0.8938\n",
      "Epoch 416/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.4857 - accuracy: 0.8219 - val_loss: 0.5180 - val_accuracy: 0.7875\n",
      "Epoch 417/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4762 - accuracy: 0.8352 - val_loss: 0.4747 - val_accuracy: 0.8594\n",
      "Epoch 418/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4600 - accuracy: 0.8555 - val_loss: 0.4705 - val_accuracy: 0.8125\n",
      "Epoch 419/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4731 - accuracy: 0.8375 - val_loss: 0.4043 - val_accuracy: 0.9000\n",
      "Epoch 420/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4778 - accuracy: 0.8344 - val_loss: 0.4131 - val_accuracy: 0.9187\n",
      "Epoch 421/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.4748 - accuracy: 0.8281 - val_loss: 0.4677 - val_accuracy: 0.8656\n",
      "Epoch 422/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4608 - accuracy: 0.8500 - val_loss: 0.5916 - val_accuracy: 0.6187\n",
      "Epoch 423/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4990 - accuracy: 0.8094 - val_loss: 0.4203 - val_accuracy: 0.8719\n",
      "Epoch 424/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4708 - accuracy: 0.8438 - val_loss: 0.4817 - val_accuracy: 0.8094\n",
      "Epoch 425/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.4648 - accuracy: 0.8273 - val_loss: 0.4099 - val_accuracy: 0.8781\n",
      "Epoch 426/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4518 - accuracy: 0.8578 - val_loss: 0.4381 - val_accuracy: 0.8438\n",
      "Epoch 427/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4643 - accuracy: 0.8438 - val_loss: 0.4427 - val_accuracy: 0.8344\n",
      "Epoch 428/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.5001 - accuracy: 0.8211 - val_loss: 0.6563 - val_accuracy: 0.7094\n",
      "Epoch 429/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4791 - accuracy: 0.8406 - val_loss: 0.4442 - val_accuracy: 0.8406\n",
      "Epoch 430/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4474 - accuracy: 0.8461 - val_loss: 0.4601 - val_accuracy: 0.8750\n",
      "Epoch 431/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4819 - accuracy: 0.8281 - val_loss: 0.4237 - val_accuracy: 0.8562\n",
      "Epoch 432/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4670 - accuracy: 0.8398 - val_loss: 0.4096 - val_accuracy: 0.8813\n",
      "Epoch 433/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4421 - accuracy: 0.8539 - val_loss: 0.4095 - val_accuracy: 0.9062\n",
      "Epoch 434/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4607 - accuracy: 0.8297 - val_loss: 0.4264 - val_accuracy: 0.8750\n",
      "Epoch 435/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4458 - accuracy: 0.8461 - val_loss: 0.4625 - val_accuracy: 0.8219\n",
      "Epoch 436/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4572 - accuracy: 0.8562 - val_loss: 0.3997 - val_accuracy: 0.8844oss: 0.4\n",
      "Epoch 437/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4631 - accuracy: 0.8484 - val_loss: 0.4160 - val_accuracy: 0.8781\n",
      "Epoch 438/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4885 - accuracy: 0.8172 - val_loss: 0.5003 - val_accuracy: 0.7844\n",
      "Epoch 439/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4466 - accuracy: 0.8492 - val_loss: 0.4850 - val_accuracy: 0.8062\n",
      "Epoch 440/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4519 - accuracy: 0.8492 - val_loss: 0.4285 - val_accuracy: 0.8531\n",
      "Epoch 441/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4431 - accuracy: 0.8484 - val_loss: 0.3955 - val_accuracy: 0.8969\n",
      "Epoch 442/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4489 - accuracy: 0.8430 - val_loss: 0.4596 - val_accuracy: 0.8281\n",
      "Epoch 443/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4517 - accuracy: 0.8500 - val_loss: 0.4033 - val_accuracy: 0.8938\n",
      "Epoch 444/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4677 - accuracy: 0.8344 - val_loss: 0.6632 - val_accuracy: 0.7000\n",
      "Epoch 445/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4415 - accuracy: 0.8477 - val_loss: 0.4028 - val_accuracy: 0.8687- accu - ETA: 0s - loss: 0.4484 - accuracy\n",
      "Epoch 446/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4535 - accuracy: 0.8422 - val_loss: 0.3977 - val_accuracy: 0.8875\n",
      "Epoch 447/800\n",
      "1280/1280 [==============================] - 3s 2ms/step - loss: 0.4520 - accuracy: 0.8398 - val_loss: 0.4146 - val_accuracy: 0.9094\n",
      "Epoch 448/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4619 - accuracy: 0.8383 - val_loss: 0.4680 - val_accuracy: 0.8125\n",
      "Epoch 449/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4367 - accuracy: 0.8539 - val_loss: 0.4396 - val_accuracy: 0.8562\n",
      "Epoch 450/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4410 - accuracy: 0.8477 - val_loss: 0.3863 - val_accuracy: 0.8875\n",
      "Epoch 451/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4489 - accuracy: 0.8523 - val_loss: 0.4083 - val_accuracy: 0.853132\n",
      "Epoch 452/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4591 - accuracy: 0.8398 - val_loss: 0.4056 - val_accuracy: 0.8531\n",
      "Epoch 453/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4345 - accuracy: 0.8523 - val_loss: 0.3774 - val_accuracy: 0.9000\n",
      "Epoch 454/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4476 - accuracy: 0.8492 - val_loss: 0.4201 - val_accuracy: 0.8656\n",
      "Epoch 455/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4305 - accuracy: 0.8531 - val_loss: 0.4665 - val_accuracy: 0.8156\n",
      "Epoch 456/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4274 - accuracy: 0.8641 - val_loss: 0.3836 - val_accuracy: 0.8844\n",
      "Epoch 457/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4215 - accuracy: 0.8578 - val_loss: 0.3819 - val_accuracy: 0.9219\n",
      "Epoch 458/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4459 - accuracy: 0.8359 - val_loss: 0.4060 - val_accuracy: 0.8438\n",
      "Epoch 459/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4511 - accuracy: 0.8477 - val_loss: 0.3977 - val_accuracy: 0.8750\n",
      "Epoch 460/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4416 - accuracy: 0.8492 - val_loss: 0.7773 - val_accuracy: 0.5844\n",
      "Epoch 461/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4395 - accuracy: 0.8461 - val_loss: 0.3715 - val_accuracy: 0.8938\n",
      "Epoch 462/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.4427 - accuracy: 0.8547 - val_loss: 0.4468 - val_accuracy: 0.8219\n",
      "Epoch 463/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4366 - accuracy: 0.8469 - val_loss: 0.5078 - val_accuracy: 0.7031\n",
      "Epoch 464/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4152 - accuracy: 0.8648 - val_loss: 0.7063 - val_accuracy: 0.5906\n",
      "Epoch 465/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4602 - accuracy: 0.8344 - val_loss: 0.4041 - val_accuracy: 0.8562\n",
      "Epoch 466/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4422 - accuracy: 0.8453 - val_loss: 0.3837 - val_accuracy: 0.9000\n",
      "Epoch 467/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4222 - accuracy: 0.8617 - val_loss: 0.4064 - val_accuracy: 0.8844\n",
      "Epoch 468/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4379 - accuracy: 0.8547 - val_loss: 0.5628 - val_accuracy: 0.7437\n",
      "Epoch 469/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4557 - accuracy: 0.8398 - val_loss: 0.3638 - val_accuracy: 0.8969\n",
      "Epoch 470/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4433 - accuracy: 0.8414 - val_loss: 0.4113 - val_accuracy: 0.8344\n",
      "Epoch 471/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4380 - accuracy: 0.8500 - val_loss: 0.3721 - val_accuracy: 0.8844\n",
      "Epoch 472/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4425 - accuracy: 0.8422 - val_loss: 1.0113 - val_accuracy: 0.5844\n",
      "Epoch 473/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4260 - accuracy: 0.8578 - val_loss: 0.3845 - val_accuracy: 0.8781\n",
      "Epoch 474/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.4370 - accuracy: 0.8570 - val_loss: 0.4976 - val_accuracy: 0.7844\n",
      "Epoch 475/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4228 - accuracy: 0.8422 - val_loss: 0.5971 - val_accuracy: 0.6500\n",
      "Epoch 476/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4354 - accuracy: 0.8484 - val_loss: 0.4761 - val_accuracy: 0.7500\n",
      "Epoch 477/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4008 - accuracy: 0.8641 - val_loss: 0.4752 - val_accuracy: 0.8000\n",
      "Epoch 478/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4485 - accuracy: 0.8406 - val_loss: 0.3686 - val_accuracy: 0.8938\n",
      "Epoch 479/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4430 - accuracy: 0.8398 - val_loss: 0.3609 - val_accuracy: 0.9062\n",
      "Epoch 480/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4182 - accuracy: 0.8547 - val_loss: 0.5188 - val_accuracy: 0.7281\n",
      "Epoch 481/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4225 - accuracy: 0.8539 - val_loss: 0.4031 - val_accuracy: 0.8625\n",
      "Epoch 482/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4305 - accuracy: 0.8438 - val_loss: 0.4305 - val_accuracy: 0.8219\n",
      "Epoch 483/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4203 - accuracy: 0.8625 - val_loss: 0.4918 - val_accuracy: 0.7625\n",
      "Epoch 484/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4110 - accuracy: 0.8562 - val_loss: 0.4126 - val_accuracy: 0.8438\n",
      "Epoch 485/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4395 - accuracy: 0.8383 - val_loss: 0.5079 - val_accuracy: 0.7469\n",
      "Epoch 486/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4254 - accuracy: 0.8516 - val_loss: 0.4146 - val_accuracy: 0.8562\n",
      "Epoch 487/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.3996 - accuracy: 0.8680 - val_loss: 0.4064 - val_accuracy: 0.8750\n",
      "Epoch 488/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4331 - accuracy: 0.8406 - val_loss: 0.3656 - val_accuracy: 0.8906\n",
      "Epoch 489/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4169 - accuracy: 0.8609 - val_loss: 0.3671 - val_accuracy: 0.8875\n",
      "Epoch 490/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4140 - accuracy: 0.8664 - val_loss: 0.3834 - val_accuracy: 0.8625\n",
      "Epoch 491/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.3967 - accuracy: 0.8680 - val_loss: 0.4040 - val_accuracy: 0.8469\n",
      "Epoch 492/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4027 - accuracy: 0.8641 - val_loss: 0.3844 - val_accuracy: 0.8656\n",
      "Epoch 493/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4155 - accuracy: 0.8656 - val_loss: 0.3674 - val_accuracy: 0.9125\n",
      "Epoch 494/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4276 - accuracy: 0.8398 - val_loss: 0.3587 - val_accuracy: 0.8906\n",
      "Epoch 495/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4212 - accuracy: 0.8453 - val_loss: 0.3468 - val_accuracy: 0.9094\n",
      "Epoch 496/800\n",
      "1280/1280 [==============================] - ETA: 0s - loss: 0.4254 - accuracy: 0.84 - 2s 2ms/step - loss: 0.4310 - accuracy: 0.8391 - val_loss: 0.5303 - val_accuracy: 0.7156\n",
      "Epoch 497/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4228 - accuracy: 0.8375 - val_loss: 0.5212 - val_accuracy: 0.7031\n",
      "Epoch 498/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4325 - accuracy: 0.8477 - val_loss: 0.4891 - val_accuracy: 0.7875\n",
      "Epoch 499/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4291 - accuracy: 0.8438 - val_loss: 0.4735 - val_accuracy: 0.8188\n",
      "Epoch 500/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4153 - accuracy: 0.8461 - val_loss: 0.5738 - val_accuracy: 0.7563\n",
      "Epoch 501/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4163 - accuracy: 0.8500 - val_loss: 0.3744 - val_accuracy: 0.8875\n",
      "Epoch 502/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.3986 - accuracy: 0.8719 - val_loss: 0.6156 - val_accuracy: 0.7375\n",
      "Epoch 503/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4246 - accuracy: 0.8484 - val_loss: 0.4238 - val_accuracy: 0.8375\n",
      "Epoch 504/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4295 - accuracy: 0.8492 - val_loss: 0.3913 - val_accuracy: 0.8531\n",
      "Epoch 505/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4276 - accuracy: 0.8523 - val_loss: 0.3729 - val_accuracy: 0.8719\n",
      "Epoch 506/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4129 - accuracy: 0.8555 - val_loss: 0.3418 - val_accuracy: 0.9062\n",
      "Epoch 507/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4154 - accuracy: 0.8594 - val_loss: 0.3887 - val_accuracy: 0.8687\n",
      "Epoch 508/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4235 - accuracy: 0.8445 - val_loss: 0.6273 - val_accuracy: 0.7156\n",
      "Epoch 509/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4095 - accuracy: 0.8539 - val_loss: 0.4466 - val_accuracy: 0.7906\n",
      "Epoch 510/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4315 - accuracy: 0.8516 - val_loss: 0.4289 - val_accuracy: 0.8562\n",
      "Epoch 511/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4038 - accuracy: 0.8633 - val_loss: 0.4185 - val_accuracy: 0.8531\n",
      "Epoch 512/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.3864 - accuracy: 0.8680 - val_loss: 0.3378 - val_accuracy: 0.8906\n",
      "Epoch 513/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4170 - accuracy: 0.8531 - val_loss: 0.4845 - val_accuracy: 0.7969\n",
      "Epoch 514/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.3778 - accuracy: 0.8797 - val_loss: 0.3418 - val_accuracy: 0.9000\n",
      "Epoch 515/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.3812 - accuracy: 0.8773 - val_loss: 0.3661 - val_accuracy: 0.8750\n",
      "Epoch 516/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4138 - accuracy: 0.8492 - val_loss: 0.3731 - val_accuracy: 0.8687\n",
      "Epoch 517/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.3932 - accuracy: 0.8672 - val_loss: 0.3434 - val_accuracy: 0.9156\n",
      "Epoch 518/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3883 - accuracy: 0.8609 - val_loss: 0.4553 - val_accuracy: 0.7844\n",
      "Epoch 519/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4218 - accuracy: 0.8477 - val_loss: 0.5577 - val_accuracy: 0.7625\n",
      "Epoch 520/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3854 - accuracy: 0.8562 - val_loss: 0.3331 - val_accuracy: 0.9125\n",
      "Epoch 521/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3935 - accuracy: 0.8680 - val_loss: 0.3410 - val_accuracy: 0.9281\n",
      "Epoch 522/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4068 - accuracy: 0.8562 - val_loss: 0.3284 - val_accuracy: 0.8969\n",
      "Epoch 523/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3788 - accuracy: 0.8672 - val_loss: 0.3766 - val_accuracy: 0.8562\n",
      "Epoch 524/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3740 - accuracy: 0.8797 - val_loss: 0.3534 - val_accuracy: 0.8687\n",
      "Epoch 525/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.4000 - accuracy: 0.8609 - val_loss: 0.4160 - val_accuracy: 0.8438\n",
      "Epoch 526/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4002 - accuracy: 0.8500 - val_loss: 0.3496 - val_accuracy: 0.9156\n",
      "Epoch 527/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4020 - accuracy: 0.8656 - val_loss: 0.4575 - val_accuracy: 0.8156\n",
      "Epoch 528/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3932 - accuracy: 0.8547 - val_loss: 0.4774 - val_accuracy: 0.7406\n",
      "Epoch 529/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3953 - accuracy: 0.8531 - val_loss: 0.4918 - val_accuracy: 0.7844\n",
      "Epoch 530/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3887 - accuracy: 0.8711 - val_loss: 0.3417 - val_accuracy: 0.8813\n",
      "Epoch 531/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3957 - accuracy: 0.8625 - val_loss: 0.3402 - val_accuracy: 0.9062\n",
      "Epoch 532/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3810 - accuracy: 0.8719 - val_loss: 0.3905 - val_accuracy: 0.8781\n",
      "Epoch 533/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4015 - accuracy: 0.8586 - val_loss: 0.5215 - val_accuracy: 0.7781\n",
      "Epoch 534/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3703 - accuracy: 0.8781 - val_loss: 0.3721 - val_accuracy: 0.8906\n",
      "Epoch 535/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3981 - accuracy: 0.8641 - val_loss: 0.3915 - val_accuracy: 0.8375\n",
      "Epoch 536/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3687 - accuracy: 0.8727 - val_loss: 0.4457 - val_accuracy: 0.8000\n",
      "Epoch 537/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3890 - accuracy: 0.8602 - val_loss: 0.3781 - val_accuracy: 0.8813\n",
      "Epoch 538/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3962 - accuracy: 0.8594 - val_loss: 0.6513 - val_accuracy: 0.7469\n",
      "Epoch 539/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4070 - accuracy: 0.8539 - val_loss: 0.3539 - val_accuracy: 0.8719\n",
      "Epoch 540/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3835 - accuracy: 0.8664 - val_loss: 0.3701 - val_accuracy: 0.8719\n",
      "Epoch 541/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3724 - accuracy: 0.8672 - val_loss: 0.3573 - val_accuracy: 0.8562\n",
      "Epoch 542/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3808 - accuracy: 0.8820 - val_loss: 0.5151 - val_accuracy: 0.7875\n",
      "Epoch 543/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.4296 - accuracy: 0.8461 - val_loss: 0.3971 - val_accuracy: 0.8469\n",
      "Epoch 544/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.4201 - accuracy: 0.8422 - val_loss: 0.3567 - val_accuracy: 0.8906\n",
      "Epoch 545/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3629 - accuracy: 0.8781 - val_loss: 0.3271 - val_accuracy: 0.8906\n",
      "Epoch 546/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3860 - accuracy: 0.8742 - val_loss: 0.3337 - val_accuracy: 0.8813\n",
      "Epoch 547/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3848 - accuracy: 0.8734 - val_loss: 0.3488 - val_accuracy: 0.9000\n",
      "Epoch 548/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3885 - accuracy: 0.8750 - val_loss: 0.3290 - val_accuracy: 0.8781\n",
      "Epoch 549/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3861 - accuracy: 0.8633 - val_loss: 0.4413 - val_accuracy: 0.8250\n",
      "Epoch 550/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3909 - accuracy: 0.8695 - val_loss: 0.3333 - val_accuracy: 0.9000\n",
      "Epoch 551/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3958 - accuracy: 0.8656 - val_loss: 0.3738 - val_accuracy: 0.8813\n",
      "Epoch 552/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.4190 - accuracy: 0.8438 - val_loss: 0.3307 - val_accuracy: 0.8938\n",
      "Epoch 553/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3750 - accuracy: 0.8750 - val_loss: 0.3426 - val_accuracy: 0.8813\n",
      "Epoch 554/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3510 - accuracy: 0.8859 - val_loss: 0.4458 - val_accuracy: 0.8156\n",
      "Epoch 555/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3802 - accuracy: 0.8680 - val_loss: 0.3754 - val_accuracy: 0.8625\n",
      "Epoch 556/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3809 - accuracy: 0.8719 - val_loss: 0.3192 - val_accuracy: 0.9031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 557/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3609 - accuracy: 0.8789 - val_loss: 0.4148 - val_accuracy: 0.8250\n",
      "Epoch 558/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3898 - accuracy: 0.8594 - val_loss: 0.3461 - val_accuracy: 0.8813\n",
      "Epoch 559/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3843 - accuracy: 0.8727 - val_loss: 0.4182 - val_accuracy: 0.8406\n",
      "Epoch 560/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3903 - accuracy: 0.8609 - val_loss: 0.4019 - val_accuracy: 0.8531\n",
      "Epoch 561/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3679 - accuracy: 0.8656 - val_loss: 0.3729 - val_accuracy: 0.8813\n",
      "Epoch 562/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3663 - accuracy: 0.8711 - val_loss: 0.3068 - val_accuracy: 0.9219\n",
      "Epoch 563/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3735 - accuracy: 0.8711 - val_loss: 0.3737 - val_accuracy: 0.8750\n",
      "Epoch 564/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.4043 - accuracy: 0.8414 - val_loss: 0.4030 - val_accuracy: 0.8313\n",
      "Epoch 565/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3799 - accuracy: 0.8633 - val_loss: 0.3253 - val_accuracy: 0.8938\n",
      "Epoch 566/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3752 - accuracy: 0.8797 - val_loss: 0.3302 - val_accuracy: 0.8875\n",
      "Epoch 567/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3927 - accuracy: 0.8578 - val_loss: 0.3244 - val_accuracy: 0.8906\n",
      "Epoch 568/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3843 - accuracy: 0.8633 - val_loss: 0.3217 - val_accuracy: 0.8719\n",
      "Epoch 569/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3805 - accuracy: 0.8672 - val_loss: 0.3233 - val_accuracy: 0.8969\n",
      "Epoch 570/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3849 - accuracy: 0.8609 - val_loss: 0.3446 - val_accuracy: 0.8781\n",
      "Epoch 571/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3657 - accuracy: 0.8703 - val_loss: 0.3073 - val_accuracy: 0.9312\n",
      "Epoch 572/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4071 - accuracy: 0.8609 - val_loss: 0.3099 - val_accuracy: 0.9344\n",
      "Epoch 573/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3635 - accuracy: 0.8680 - val_loss: 0.3140 - val_accuracy: 0.8969\n",
      "Epoch 574/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3878 - accuracy: 0.8703 - val_loss: 0.3394 - val_accuracy: 0.8750\n",
      "Epoch 575/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.3496 - accuracy: 0.8883 - val_loss: 0.3566 - val_accuracy: 0.8781\n",
      "Epoch 576/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.3941 - accuracy: 0.8617 - val_loss: 0.3512 - val_accuracy: 0.8562\n",
      "Epoch 577/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3858 - accuracy: 0.8672 - val_loss: 0.4119 - val_accuracy: 0.8469\n",
      "Epoch 578/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3457 - accuracy: 0.8875 - val_loss: 0.3083 - val_accuracy: 0.8938\n",
      "Epoch 579/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3836 - accuracy: 0.8656 - val_loss: 0.3048 - val_accuracy: 0.9094\n",
      "Epoch 580/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.3579 - accuracy: 0.8781 - val_loss: 0.3034 - val_accuracy: 0.9187\n",
      "Epoch 581/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3499 - accuracy: 0.8813 - val_loss: 0.3181 - val_accuracy: 0.9031\n",
      "Epoch 582/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3881 - accuracy: 0.8633 - val_loss: 0.3418 - val_accuracy: 0.8813\n",
      "Epoch 583/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4306 - accuracy: 0.8391 - val_loss: 0.2984 - val_accuracy: 0.9062\n",
      "Epoch 584/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3574 - accuracy: 0.8781 - val_loss: 0.3060 - val_accuracy: 0.9062\n",
      "Epoch 585/800\n",
      "1280/1280 [==============================] - ETA: 0s - loss: 0.3560 - accuracy: 0.87 - 2s 1ms/step - loss: 0.3569 - accuracy: 0.8773 - val_loss: 0.3511 - val_accuracy: 0.8813\n",
      "Epoch 586/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3849 - accuracy: 0.8656 - val_loss: 0.3083 - val_accuracy: 0.9094\n",
      "Epoch 587/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3673 - accuracy: 0.8680 - val_loss: 0.3932 - val_accuracy: 0.8313\n",
      "Epoch 588/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3463 - accuracy: 0.8805 - val_loss: 0.3726 - val_accuracy: 0.8719\n",
      "Epoch 589/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3585 - accuracy: 0.8703 - val_loss: 0.3106 - val_accuracy: 0.8906\n",
      "Epoch 590/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3517 - accuracy: 0.8805 - val_loss: 0.3265 - val_accuracy: 0.8719\n",
      "Epoch 591/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3736 - accuracy: 0.8758 - val_loss: 0.2996 - val_accuracy: 0.9219\n",
      "Epoch 592/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3817 - accuracy: 0.8594 - val_loss: 0.3532 - val_accuracy: 0.9125\n",
      "Epoch 593/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3653 - accuracy: 0.8672 - val_loss: 0.3079 - val_accuracy: 0.8906\n",
      "Epoch 594/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3942 - accuracy: 0.8602 - val_loss: 0.3001 - val_accuracy: 0.9344\n",
      "Epoch 595/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3523 - accuracy: 0.8805 - val_loss: 0.3752 - val_accuracy: 0.8469\n",
      "Epoch 596/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3510 - accuracy: 0.8836 - val_loss: 0.3489 - val_accuracy: 0.8531\n",
      "Epoch 597/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3525 - accuracy: 0.8727 - val_loss: 0.3131 - val_accuracy: 0.9094\n",
      "Epoch 598/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3645 - accuracy: 0.8766 - val_loss: 0.3366 - val_accuracy: 0.8719\n",
      "Epoch 599/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3461 - accuracy: 0.8875 - val_loss: 0.4081 - val_accuracy: 0.8313\n",
      "Epoch 600/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3623 - accuracy: 0.8758 - val_loss: 0.3097 - val_accuracy: 0.9031\n",
      "Epoch 601/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.3703 - accuracy: 0.8687 - val_loss: 0.3776 - val_accuracy: 0.8562\n",
      "Epoch 602/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3435 - accuracy: 0.8852 - val_loss: 0.3296 - val_accuracy: 0.8656\n",
      "Epoch 603/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3436 - accuracy: 0.8891 - val_loss: 0.3278 - val_accuracy: 0.9031\n",
      "Epoch 604/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3655 - accuracy: 0.8719 - val_loss: 0.3284 - val_accuracy: 0.8906\n",
      "Epoch 605/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3456 - accuracy: 0.8789 - val_loss: 0.3621 - val_accuracy: 0.8469\n",
      "Epoch 606/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3862 - accuracy: 0.8539 - val_loss: 0.3817 - val_accuracy: 0.8625\n",
      "Epoch 607/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3149 - accuracy: 0.8969 - val_loss: 0.3477 - val_accuracy: 0.8875\n",
      "Epoch 608/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3369 - accuracy: 0.8859 - val_loss: 0.2878 - val_accuracy: 0.9281\n",
      "Epoch 609/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3587 - accuracy: 0.8687 - val_loss: 0.6578 - val_accuracy: 0.6187\n",
      "Epoch 610/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3419 - accuracy: 0.8820 - val_loss: 0.3226 - val_accuracy: 0.8750\n",
      "Epoch 611/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3900 - accuracy: 0.8531 - val_loss: 0.2965 - val_accuracy: 0.8938\n",
      "Epoch 612/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3569 - accuracy: 0.8781 - val_loss: 0.3054 - val_accuracy: 0.9000\n",
      "Epoch 613/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3258 - accuracy: 0.8891 - val_loss: 0.3020 - val_accuracy: 0.9031\n",
      "Epoch 614/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3424 - accuracy: 0.8836 - val_loss: 0.3076 - val_accuracy: 0.9000\n",
      "Epoch 615/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3952 - accuracy: 0.8594 - val_loss: 0.4015 - val_accuracy: 0.8562\n",
      "Epoch 616/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3395 - accuracy: 0.8773 - val_loss: 0.4883 - val_accuracy: 0.7937\n",
      "Epoch 617/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3491 - accuracy: 0.8820 - val_loss: 0.3122 - val_accuracy: 0.8781\n",
      "Epoch 618/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3577 - accuracy: 0.8766 - val_loss: 0.3138 - val_accuracy: 0.8844\n",
      "Epoch 619/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3994 - accuracy: 0.8516 - val_loss: 0.3554 - val_accuracy: 0.8531\n",
      "Epoch 620/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3636 - accuracy: 0.8656 - val_loss: 0.3059 - val_accuracy: 0.9062\n",
      "Epoch 621/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3428 - accuracy: 0.8766 - val_loss: 0.2876 - val_accuracy: 0.9094\n",
      "Epoch 622/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3307 - accuracy: 0.8898 - val_loss: 0.3137 - val_accuracy: 0.8875\n",
      "Epoch 623/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3509 - accuracy: 0.8797 - val_loss: 0.3114 - val_accuracy: 0.8719\n",
      "Epoch 624/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3561 - accuracy: 0.8766 - val_loss: 0.3241 - val_accuracy: 0.8687\n",
      "Epoch 625/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3659 - accuracy: 0.8578 - val_loss: 0.2956 - val_accuracy: 0.9031\n",
      "Epoch 626/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3321 - accuracy: 0.8859 - val_loss: 0.2860 - val_accuracy: 0.9031\n",
      "Epoch 627/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3359 - accuracy: 0.8852 - val_loss: 0.3281 - val_accuracy: 0.9000\n",
      "Epoch 628/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3398 - accuracy: 0.8844 - val_loss: 0.2957 - val_accuracy: 0.9250\n",
      "Epoch 629/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3264 - accuracy: 0.8914 - val_loss: 0.3903 - val_accuracy: 0.8281\n",
      "Epoch 630/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3282 - accuracy: 0.8883 - val_loss: 0.2912 - val_accuracy: 0.9031\n",
      "Epoch 631/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3579 - accuracy: 0.8742 - val_loss: 0.3516 - val_accuracy: 0.8656\n",
      "Epoch 632/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3822 - accuracy: 0.8750 - val_loss: 0.2873 - val_accuracy: 0.9250\n",
      "Epoch 633/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3265 - accuracy: 0.8898 - val_loss: 0.3169 - val_accuracy: 0.8875\n",
      "Epoch 634/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3254 - accuracy: 0.8953 - val_loss: 0.3841 - val_accuracy: 0.8469\n",
      "Epoch 635/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3357 - accuracy: 0.8836 - val_loss: 0.4166 - val_accuracy: 0.7937\n",
      "Epoch 636/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3637 - accuracy: 0.8687 - val_loss: 0.3308 - val_accuracy: 0.9062\n",
      "Epoch 637/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3289 - accuracy: 0.8828 - val_loss: 0.3203 - val_accuracy: 0.8938\n",
      "Epoch 638/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3521 - accuracy: 0.8687 - val_loss: 0.2810 - val_accuracy: 0.9281\n",
      "Epoch 639/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3348 - accuracy: 0.8742 - val_loss: 0.2879 - val_accuracy: 0.9094\n",
      "Epoch 640/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3374 - accuracy: 0.8719 - val_loss: 0.2831 - val_accuracy: 0.9094\n",
      "Epoch 641/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.3277 - accuracy: 0.8906 - val_loss: 0.3696 - val_accuracy: 0.8438\n",
      "Epoch 642/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3354 - accuracy: 0.8867 - val_loss: 0.2912 - val_accuracy: 0.8906\n",
      "Epoch 643/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3617 - accuracy: 0.8570 - val_loss: 0.3552 - val_accuracy: 0.8500\n",
      "Epoch 644/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3467 - accuracy: 0.8859 - val_loss: 0.3577 - val_accuracy: 0.8875\n",
      "Epoch 645/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3377 - accuracy: 0.8727 - val_loss: 0.3914 - val_accuracy: 0.8313\n",
      "Epoch 646/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3187 - accuracy: 0.8859 - val_loss: 0.3669 - val_accuracy: 0.8469\n",
      "Epoch 647/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3542 - accuracy: 0.8703 - val_loss: 0.2871 - val_accuracy: 0.9187\n",
      "Epoch 648/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3425 - accuracy: 0.8750 - val_loss: 0.3319 - val_accuracy: 0.8781\n",
      "Epoch 649/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3592 - accuracy: 0.8742 - val_loss: 0.3788 - val_accuracy: 0.8375\n",
      "Epoch 650/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3186 - accuracy: 0.8922 - val_loss: 0.3849 - val_accuracy: 0.8438\n",
      "Epoch 651/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3236 - accuracy: 0.8906 - val_loss: 0.2860 - val_accuracy: 0.9406\n",
      "Epoch 652/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3353 - accuracy: 0.8852 - val_loss: 0.2733 - val_accuracy: 0.9156\n",
      "Epoch 653/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3307 - accuracy: 0.8750 - val_loss: 0.3300 - val_accuracy: 0.9062\n",
      "Epoch 654/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.3515 - accuracy: 0.8672 - val_loss: 0.3643 - val_accuracy: 0.8562\n",
      "Epoch 655/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2963 - accuracy: 0.9023 - val_loss: 0.3924 - val_accuracy: 0.8531\n",
      "Epoch 656/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3354 - accuracy: 0.8805 - val_loss: 0.3944 - val_accuracy: 0.8531\n",
      "Epoch 657/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3404 - accuracy: 0.8734 - val_loss: 0.2951 - val_accuracy: 0.8687\n",
      "Epoch 658/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3399 - accuracy: 0.8773 - val_loss: 0.6792 - val_accuracy: 0.6156\n",
      "Epoch 659/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3433 - accuracy: 0.8859 - val_loss: 0.2836 - val_accuracy: 0.9156\n",
      "Epoch 660/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3261 - accuracy: 0.8836 - val_loss: 0.2912 - val_accuracy: 0.9031\n",
      "Epoch 661/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3345 - accuracy: 0.8797 - val_loss: 0.3472 - val_accuracy: 0.8562\n",
      "Epoch 662/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3236 - accuracy: 0.8875 - val_loss: 0.3079 - val_accuracy: 0.8719\n",
      "Epoch 663/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3387 - accuracy: 0.8891 - val_loss: 0.4662 - val_accuracy: 0.7437\n",
      "Epoch 664/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3150 - accuracy: 0.8984 - val_loss: 0.3587 - val_accuracy: 0.8687\n",
      "Epoch 665/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3175 - accuracy: 0.8938 - val_loss: 0.2998 - val_accuracy: 0.8875\n",
      "Epoch 666/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3343 - accuracy: 0.8773 - val_loss: 0.3620 - val_accuracy: 0.8344\n",
      "Epoch 667/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3179 - accuracy: 0.8875 - val_loss: 0.3583 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 668/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3298 - accuracy: 0.8758 - val_loss: 0.3211 - val_accuracy: 0.8719\n",
      "Epoch 669/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3418 - accuracy: 0.8734 - val_loss: 0.3212 - val_accuracy: 0.8969\n",
      "Epoch 670/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3690 - accuracy: 0.8633 - val_loss: 0.6335 - val_accuracy: 0.7625\n",
      "Epoch 671/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3338 - accuracy: 0.8875 - val_loss: 0.5977 - val_accuracy: 0.6781\n",
      "Epoch 672/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3094 - accuracy: 0.8938 - val_loss: 0.3064 - val_accuracy: 0.9156\n",
      "Epoch 673/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3428 - accuracy: 0.8695 - val_loss: 0.2801 - val_accuracy: 0.9281\n",
      "Epoch 674/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3289 - accuracy: 0.8813 - val_loss: 0.2701 - val_accuracy: 0.9219\n",
      "Epoch 675/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3197 - accuracy: 0.8914 - val_loss: 0.3244 - val_accuracy: 0.8813\n",
      "Epoch 676/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3122 - accuracy: 0.8820 - val_loss: 0.3320 - val_accuracy: 0.8938\n",
      "Epoch 677/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3114 - accuracy: 0.8914 - val_loss: 0.2870 - val_accuracy: 0.9031\n",
      "Epoch 678/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3231 - accuracy: 0.8844 - val_loss: 0.3262 - val_accuracy: 0.8781\n",
      "Epoch 679/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3505 - accuracy: 0.8789 - val_loss: 0.2803 - val_accuracy: 0.9375\n",
      "Epoch 680/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3531 - accuracy: 0.8734 - val_loss: 0.2788 - val_accuracy: 0.9187\n",
      "Epoch 681/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3059 - accuracy: 0.8945 - val_loss: 0.4253 - val_accuracy: 0.8344\n",
      "Epoch 682/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3284 - accuracy: 0.8867 - val_loss: 0.2935 - val_accuracy: 0.9031\n",
      "Epoch 683/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3193 - accuracy: 0.8852 - val_loss: 0.2633 - val_accuracy: 0.9187\n",
      "Epoch 684/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3285 - accuracy: 0.8805 - val_loss: 0.3686 - val_accuracy: 0.8313\n",
      "Epoch 685/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3062 - accuracy: 0.8984 - val_loss: 0.3951 - val_accuracy: 0.8375\n",
      "Epoch 686/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3101 - accuracy: 0.8883 - val_loss: 0.4669 - val_accuracy: 0.7500\n",
      "Epoch 687/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3310 - accuracy: 0.8898 - val_loss: 0.3200 - val_accuracy: 0.8875\n",
      "Epoch 688/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.2967 - accuracy: 0.8961 - val_loss: 0.2790 - val_accuracy: 0.9031\n",
      "Epoch 689/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3379 - accuracy: 0.8820 - val_loss: 0.3264 - val_accuracy: 0.8969\n",
      "Epoch 690/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3411 - accuracy: 0.8711 - val_loss: 0.4645 - val_accuracy: 0.8219\n",
      "Epoch 691/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2947 - accuracy: 0.9031 - val_loss: 0.2743 - val_accuracy: 0.8844\n",
      "Epoch 692/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3167 - accuracy: 0.8789 - val_loss: 0.2731 - val_accuracy: 0.9094\n",
      "Epoch 693/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3275 - accuracy: 0.8875 - val_loss: 0.2930 - val_accuracy: 0.9187\n",
      "Epoch 694/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3317 - accuracy: 0.8938 - val_loss: 0.2665 - val_accuracy: 0.9062\n",
      "Epoch 695/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3241 - accuracy: 0.8852 - val_loss: 0.3257 - val_accuracy: 0.8781\n",
      "Epoch 696/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3117 - accuracy: 0.8977 - val_loss: 0.2967 - val_accuracy: 0.8969\n",
      "Epoch 697/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3168 - accuracy: 0.8922 - val_loss: 0.2664 - val_accuracy: 0.9312\n",
      "Epoch 698/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3149 - accuracy: 0.8938 - val_loss: 0.2664 - val_accuracy: 0.9156\n",
      "Epoch 699/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3181 - accuracy: 0.8914 - val_loss: 0.2724 - val_accuracy: 0.8938\n",
      "Epoch 700/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3246 - accuracy: 0.8813 - val_loss: 0.2770 - val_accuracy: 0.9031\n",
      "Epoch 701/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2994 - accuracy: 0.8961 - val_loss: 0.3182 - val_accuracy: 0.8656\n",
      "Epoch 702/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3148 - accuracy: 0.8852 - val_loss: 0.2970 - val_accuracy: 0.8969\n",
      "Epoch 703/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2994 - accuracy: 0.8914 - val_loss: 0.3949 - val_accuracy: 0.8438\n",
      "Epoch 704/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3049 - accuracy: 0.8914 - val_loss: 0.2870 - val_accuracy: 0.9187\n",
      "Epoch 705/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3093 - accuracy: 0.8875 - val_loss: 0.3400 - val_accuracy: 0.8687\n",
      "Epoch 706/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2971 - accuracy: 0.8914 - val_loss: 0.2648 - val_accuracy: 0.9125\n",
      "Epoch 707/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2959 - accuracy: 0.8945 - val_loss: 0.4240 - val_accuracy: 0.7937\n",
      "Epoch 708/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3677 - accuracy: 0.8703 - val_loss: 0.3086 - val_accuracy: 0.8781\n",
      "Epoch 709/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2978 - accuracy: 0.8898 - val_loss: 0.2904 - val_accuracy: 0.8906\n",
      "Epoch 710/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3135 - accuracy: 0.8867 - val_loss: 0.2833 - val_accuracy: 0.8938\n",
      "Epoch 711/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3128 - accuracy: 0.8867 - val_loss: 0.2682 - val_accuracy: 0.9094\n",
      "Epoch 712/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3129 - accuracy: 0.8891 - val_loss: 0.2772 - val_accuracy: 0.9000\n",
      "Epoch 713/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3259 - accuracy: 0.8883 - val_loss: 0.3077 - val_accuracy: 0.9062\n",
      "Epoch 714/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3019 - accuracy: 0.8992 - val_loss: 0.2546 - val_accuracy: 0.9000\n",
      "Epoch 715/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3270 - accuracy: 0.8750 - val_loss: 0.3894 - val_accuracy: 0.8125\n",
      "Epoch 716/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3031 - accuracy: 0.8836 - val_loss: 0.7761 - val_accuracy: 0.7063\n",
      "Epoch 717/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2852 - accuracy: 0.9078 - val_loss: 0.4318 - val_accuracy: 0.7656\n",
      "Epoch 718/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3296 - accuracy: 0.8797 - val_loss: 0.3502 - val_accuracy: 0.8531\n",
      "Epoch 719/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3015 - accuracy: 0.9039 - val_loss: 0.5982 - val_accuracy: 0.7469\n",
      "Epoch 720/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3083 - accuracy: 0.8844 - val_loss: 0.4023 - val_accuracy: 0.8094\n",
      "Epoch 721/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3192 - accuracy: 0.8859 - val_loss: 0.2623 - val_accuracy: 0.9187\n",
      "Epoch 722/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3027 - accuracy: 0.8945 - val_loss: 0.2630 - val_accuracy: 0.8906\n",
      "Epoch 723/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3322 - accuracy: 0.8750 - val_loss: 0.4249 - val_accuracy: 0.7781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 724/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3158 - accuracy: 0.8898 - val_loss: 0.2640 - val_accuracy: 0.9062\n",
      "Epoch 725/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2987 - accuracy: 0.8977 - val_loss: 0.3719 - val_accuracy: 0.8375\n",
      "Epoch 726/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2791 - accuracy: 0.8992 - val_loss: 0.2633 - val_accuracy: 0.9375\n",
      "Epoch 727/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2956 - accuracy: 0.8977 - val_loss: 0.3072 - val_accuracy: 0.8906\n",
      "Epoch 728/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3402 - accuracy: 0.8781 - val_loss: 0.2852 - val_accuracy: 0.8938\n",
      "Epoch 729/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2774 - accuracy: 0.9070 - val_loss: 0.2501 - val_accuracy: 0.9375\n",
      "Epoch 730/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2848 - accuracy: 0.8977 - val_loss: 0.2943 - val_accuracy: 0.8969 - loss: 0.2868 - accuracy: 0.\n",
      "Epoch 731/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2941 - accuracy: 0.8969 - val_loss: 0.2623 - val_accuracy: 0.9125\n",
      "Epoch 732/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3026 - accuracy: 0.8977 - val_loss: 0.2561 - val_accuracy: 0.9000\n",
      "Epoch 733/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2908 - accuracy: 0.9031 - val_loss: 0.3578 - val_accuracy: 0.8719\n",
      "Epoch 734/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2789 - accuracy: 0.9109 - val_loss: 0.2693 - val_accuracy: 0.8969\n",
      "Epoch 735/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3097 - accuracy: 0.8961 - val_loss: 0.2964 - val_accuracy: 0.8938\n",
      "Epoch 736/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3110 - accuracy: 0.8922 - val_loss: 0.2518 - val_accuracy: 0.9156\n",
      "Epoch 737/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3011 - accuracy: 0.8938 - val_loss: 0.4025 - val_accuracy: 0.7844\n",
      "Epoch 738/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2795 - accuracy: 0.9000 - val_loss: 0.2921 - val_accuracy: 0.8719\n",
      "Epoch 739/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3174 - accuracy: 0.8836 - val_loss: 0.2892 - val_accuracy: 0.9219\n",
      "Epoch 740/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3036 - accuracy: 0.8977 - val_loss: 0.5153 - val_accuracy: 0.7125\n",
      "Epoch 741/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3056 - accuracy: 0.8836 - val_loss: 0.2574 - val_accuracy: 0.9250\n",
      "Epoch 742/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2981 - accuracy: 0.8945 - val_loss: 0.2538 - val_accuracy: 0.9062\n",
      "Epoch 743/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.2877 - accuracy: 0.9016 - val_loss: 0.2900 - val_accuracy: 0.8969\n",
      "Epoch 744/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.2919 - accuracy: 0.9016 - val_loss: 0.2989 - val_accuracy: 0.9250\n",
      "Epoch 745/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3351 - accuracy: 0.8703 - val_loss: 0.2501 - val_accuracy: 0.9375\n",
      "Epoch 746/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3310 - accuracy: 0.8766 - val_loss: 0.3232 - val_accuracy: 0.8594\n",
      "Epoch 747/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3033 - accuracy: 0.8898 - val_loss: 0.2535 - val_accuracy: 0.9187\n",
      "Epoch 748/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3068 - accuracy: 0.8914 - val_loss: 0.2626 - val_accuracy: 0.9156\n",
      "Epoch 749/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2828 - accuracy: 0.9086 - val_loss: 0.3161 - val_accuracy: 0.8781\n",
      "Epoch 750/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2694 - accuracy: 0.9156 - val_loss: 0.2758 - val_accuracy: 0.8875\n",
      "Epoch 751/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2974 - accuracy: 0.8938 - val_loss: 0.2471 - val_accuracy: 0.9312\n",
      "Epoch 752/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3169 - accuracy: 0.8750 - val_loss: 0.2415 - val_accuracy: 0.9344\n",
      "Epoch 753/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3116 - accuracy: 0.8961 - val_loss: 0.3151 - val_accuracy: 0.9062\n",
      "Epoch 754/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3016 - accuracy: 0.8922 - val_loss: 0.2508 - val_accuracy: 0.9344\n",
      "Epoch 755/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2948 - accuracy: 0.9055 - val_loss: 0.2929 - val_accuracy: 0.8906\n",
      "Epoch 756/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3095 - accuracy: 0.9008 - val_loss: 0.2612 - val_accuracy: 0.9375\n",
      "Epoch 757/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2713 - accuracy: 0.9055 - val_loss: 0.2843 - val_accuracy: 0.8750\n",
      "Epoch 758/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2784 - accuracy: 0.8961 - val_loss: 0.2445 - val_accuracy: 0.9375\n",
      "Epoch 759/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.3137 - accuracy: 0.8820 - val_loss: 0.3125 - val_accuracy: 0.8875\n",
      "Epoch 760/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.2820 - accuracy: 0.9008 - val_loss: 0.4143 - val_accuracy: 0.7906\n",
      "Epoch 761/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.3054 - accuracy: 0.8906 - val_loss: 0.2528 - val_accuracy: 0.9000\n",
      "Epoch 762/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3133 - accuracy: 0.8891 - val_loss: 0.2934 - val_accuracy: 0.8875\n",
      "Epoch 763/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3343 - accuracy: 0.8781 - val_loss: 0.2451 - val_accuracy: 0.9094\n",
      "Epoch 764/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2772 - accuracy: 0.9078 - val_loss: 0.2413 - val_accuracy: 0.9156\n",
      "Epoch 765/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.3163 - accuracy: 0.8906 - val_loss: 0.3068 - val_accuracy: 0.9156\n",
      "Epoch 766/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3137 - accuracy: 0.8828 - val_loss: 0.2497 - val_accuracy: 0.9312\n",
      "Epoch 767/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.2751 - accuracy: 0.9148 - val_loss: 0.2550 - val_accuracy: 0.9125\n",
      "Epoch 768/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.3197 - accuracy: 0.8797 - val_loss: 0.2462 - val_accuracy: 0.9375\n",
      "Epoch 769/800\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.2913 - accuracy: 0.8938 - val_loss: 0.2496 - val_accuracy: 0.9156\n",
      "Epoch 770/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2796 - accuracy: 0.9078 - val_loss: 0.2902 - val_accuracy: 0.8875\n",
      "Epoch 771/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3050 - accuracy: 0.8914 - val_loss: 0.3512 - val_accuracy: 0.8687\n",
      "Epoch 772/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.2958 - accuracy: 0.8945 - val_loss: 0.4251 - val_accuracy: 0.8344\n",
      "Epoch 773/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.2725 - accuracy: 0.9109 - val_loss: 0.2596 - val_accuracy: 0.9281\n",
      "Epoch 774/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.2998 - accuracy: 0.8867 - val_loss: 0.2720 - val_accuracy: 0.9000\n",
      "Epoch 775/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.2813 - accuracy: 0.9055 - val_loss: 0.3050 - val_accuracy: 0.8813\n",
      "Epoch 776/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2784 - accuracy: 0.9062 - val_loss: 0.2834 - val_accuracy: 0.9156\n",
      "Epoch 777/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3173 - accuracy: 0.8891 - val_loss: 0.2365 - val_accuracy: 0.9375\n",
      "Epoch 778/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3064 - accuracy: 0.8914 - val_loss: 0.2618 - val_accuracy: 0.9031\n",
      "Epoch 779/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3243 - accuracy: 0.8844 - val_loss: 0.2437 - val_accuracy: 0.9125\n",
      "Epoch 780/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2944 - accuracy: 0.8992 - val_loss: 0.3314 - val_accuracy: 0.8687\n",
      "Epoch 781/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2855 - accuracy: 0.8977 - val_loss: 0.2795 - val_accuracy: 0.8969\n",
      "Epoch 782/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2892 - accuracy: 0.9008 - val_loss: 0.3115 - val_accuracy: 0.8813\n",
      "Epoch 783/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.3054 - accuracy: 0.8922 - val_loss: 0.2769 - val_accuracy: 0.8938\n",
      "Epoch 784/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2686 - accuracy: 0.9125 - val_loss: 0.2359 - val_accuracy: 0.9344\n",
      "Epoch 785/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3495 - accuracy: 0.8813 - val_loss: 0.3601 - val_accuracy: 0.8562\n",
      "Epoch 786/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2802 - accuracy: 0.9031 - val_loss: 0.2824 - val_accuracy: 0.9031\n",
      "Epoch 787/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3038 - accuracy: 0.8898 - val_loss: 0.2998 - val_accuracy: 0.8875\n",
      "Epoch 788/800\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.2974 - accuracy: 0.8930 - val_loss: 0.2488 - val_accuracy: 0.9219\n",
      "Epoch 789/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2741 - accuracy: 0.8992 - val_loss: 0.2632 - val_accuracy: 0.9031\n",
      "Epoch 790/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2828 - accuracy: 0.9133 - val_loss: 0.2488 - val_accuracy: 0.9250\n",
      "Epoch 791/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2904 - accuracy: 0.8938 - val_loss: 0.2351 - val_accuracy: 0.9312\n",
      "Epoch 792/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2711 - accuracy: 0.9031 - val_loss: 0.2882 - val_accuracy: 0.8906\n",
      "Epoch 793/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2667 - accuracy: 0.9102 - val_loss: 0.3066 - val_accuracy: 0.8813\n",
      "Epoch 794/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2936 - accuracy: 0.8930 - val_loss: 0.2758 - val_accuracy: 0.8938\n",
      "Epoch 795/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2781 - accuracy: 0.8992 - val_loss: 0.2334 - val_accuracy: 0.9187\n",
      "Epoch 796/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3052 - accuracy: 0.8953 - val_loss: 0.2562 - val_accuracy: 0.9031\n",
      "Epoch 797/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3056 - accuracy: 0.8813 - val_loss: 0.3039 - val_accuracy: 0.8906\n",
      "Epoch 798/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2813 - accuracy: 0.8992 - val_loss: 0.2397 - val_accuracy: 0.9187\n",
      "Epoch 799/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2696 - accuracy: 0.8961 - val_loss: 0.2722 - val_accuracy: 0.9156\n",
      "Epoch 800/800\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2794 - accuracy: 0.9062 - val_loss: 0.2319 - val_accuracy: 0.9094\n",
      "Train: 0.930, Test: 0.909\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parte 2 - Classificação dos sinais do Elevador\n",
    "import random\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from matplotlib import pyplot\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# define model\n",
    "opt = SGD(lr=0.001) # aqui é colocado a taxa de aprendizagem\n",
    "                     # SGD indica que está usando a técnica de gradiente descendente estocástico para otimizar a MLP\n",
    "                     # Essa técnica de otimização é a mais usada e é a que se aprende quando se lê sobre redes neurais \n",
    "model = Sequential()\n",
    "model.add(Dense(850, input_dim=850, activation='sigmoid'))  # input_dim é o tamanho da entrada\n",
    "#model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax')) # o número '4' deve ser a quantidade de classes que a rede vai classificar\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "# patient early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=120)\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=400, verbose=1, callbacks=[es], batch_size=10)\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0) #usado para testar a acurácia do modelo\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
